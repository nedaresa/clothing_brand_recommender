{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "#!pip install openai -U\n",
    "from openai import OpenAI\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
    "model = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get human emotions  \n",
    "\n",
    "# Define the Pydantic model for the API response\n",
    "class EmotionsResponse(BaseModel):\n",
    "    Characteristics: List[str] = Field(None, description=\"List of non-redundant human emotions.\")\n",
    "\n",
    "def get_emotions(model: str) -> List[str]:\n",
    "    \"\"\"Gets a list of 50 non-redundant human emotions using the specified gpt model.\"\"\"\n",
    "    \n",
    "    # Define system and user prompts\n",
    "    system_prompt = \"Find 50 non-redundant and different human emotions. \"\\\n",
    "    \"For example, from each of these four emotion groups, only select one representative\"\\\n",
    "    \": 1: joy, happiness, 2: Shame, Embarrassment, \"\\\n",
    "    \"3: Envy, Jealousy , 4: Hate, disgust, hatered, Resentment. \"\\\n",
    "    \"So on and so forth.\"\n",
    "\n",
    "    user_prompt = \"Select 50 non-redundant and different human emotions.\"\n",
    "\n",
    "    try:\n",
    "        #Call the API to get the completion\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model= model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Be a helpful assistant.\"},\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"system\", \"content\": \"Did you accidentally select multiple emotions from the four emotion groups? If so, keep only one representative from each group and drop the rest.\"},\n",
    "                {\"role\": \"system\", \"content\": \"Check again for redundancy. Remember, you must only select emotions describing non-redundant human feelings.\"},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            response_format=EmotionsResponse\n",
    "        )\n",
    "\n",
    "        #output returns in the defined pydantic style\n",
    "        output = completion.choices[0].message.parsed\n",
    "        return output.json()\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle exceptions such as API errors, etc\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example usage\n",
    "emotions = get_emotions(model= model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to check emotion redundancy by looking at example groups \n",
    "#[i for i in list(json.loads(emotions).values())[0] if i in ['Joy', 'Happiness', 'Shame', 'Embarrassment', 'Envy', 'Jealousy' , 'Hate', 'disgust', 'hatered', 'Resentment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get 100 best selling American clothing brands \n",
    "\n",
    "# Define the Pydantic model for the API response\n",
    "class BrandsResponse(BaseModel):\n",
    "    Brands: List[str] = Field(None, description=\"Brands as a list of strings.\")\n",
    "\n",
    "def get_brands(model: str) -> List[str]:\n",
    "    \"\"\"Get 100 best selling American clothing brands using the specified gpt model.\"\"\"\n",
    "\n",
    "    try:\n",
    "        #Call the API to get the completion\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model= model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Be a helpful assistant.\"},\n",
    "                {\"role\": \"system\", \"content\": \"Find 100 non-redundant best selling American clothing brands.\"},\n",
    "                {\"role\": \"system\", \"content\": \"DONT MAKE ANY MISTAKES, check if you did any.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Give me 100 best selling American clothing brands.\"}\n",
    "            ],\n",
    "            response_format=BrandsResponse\n",
    "        )\n",
    "\n",
    "        #output returns in the defined pydantic style\n",
    "        output = completion.choices[0].message.parsed\n",
    "        return output.json()\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle exceptions such as API errors, etc\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example usage\n",
    "brands = get_brands(model= model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_ls = list(json.loads(emotions).values())[0]\n",
    "brands_ls = list(json.loads(brands).values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding brand in emotions space: Get association scores between an input and list of emotions\n",
    "\n",
    "Characteristic = Enum('Characteristic', dict([(emotion, emotion) for emotion in emotions_ls]))\n",
    "\n",
    "class EmotionalAssociationScore(BaseModel):\n",
    "    emotion: Characteristic\n",
    "    score: float\n",
    "\n",
    "class EmotionalAssociationScores(BaseModel):\n",
    "    associations: List[EmotionalAssociationScore] = Field(description=\"A list of emotions and associated scores\")\n",
    "\n",
    "def emotional_association_scores(\n",
    "        thing, \n",
    "        model,\n",
    "        emotions\n",
    "    ):\n",
    "    \n",
    "    prompt = f\"Assign emotional association scores between {0} and {len(emotions)} for the provided thing. \"\\\n",
    "    \"Assign a score for each of the following emotions. Briefly, explain the reason behind the association score.\"\\\n",
    "    \"Ensure the scores reflect the association strength for the specified thing. \"\\\n",
    "    \"Thing: \"\\\n",
    "    f\"{thing}\"\n",
    "            \n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model = model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Be a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=EmotionalAssociationScores,\n",
    "    )\n",
    "    #output returns in the defined pydantic style\n",
    "    output = completion.choices[0].message.parsed\n",
    "    return thing, output.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not using this for the moment\n",
    "# #Embedding brands in emotions space: \n",
    "# # tried nested prompt but decided to go with one prompt and a list comprehension\n",
    "# emotions= emotions_ls\n",
    "# associations_brands = [emotional_association_scores(thing, model, emotions) for thing in brands_ls[:3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(thing, model, emotions):\n",
    "    gpt = emotional_association_scores(thing, model, emotions)\n",
    "    data = list(json.loads(gpt[1]).values())[0]\n",
    "    df = pd.DataFrame(data)\n",
    "    df.rename(columns = {'score': gpt[0]}, inplace=True)\n",
    "    df.set_index('emotion', inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_dfs(things_ls, model, emotions):\n",
    "    merged_df = pd.DataFrame()\n",
    "    for thing in things_ls[:2]:\n",
    "        new_df = get_df(thing, model, emotions)\n",
    "        if merged_df.empty:\n",
    "            merged_df = new_df\n",
    "        else:\n",
    "            merged_df = pd.merge(merged_df, new_df, left_index=True, right_index=True, how='outer')\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "things_ls = brands_ls\n",
    "dfs = get_dfs(things_ls, model, emotions)\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding a book in emotions space: \n",
    "emotions= emotions_ls\n",
    "thing = 'Summer Island'\n",
    "df = get_df(thing, model, emotions)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define your vectors\n",
    "A = np.array([[2, 3]])\n",
    "B = np.array([[5, 4]])\n",
    "\n",
    "def_get_norm(series):\n",
    "    # L2 normalize the vectors\n",
    "    series_normalized = normalize(series, norm='l2')\n",
    "\n",
    "# Calculate cosine similarity on normalized vectors\n",
    "similarity = cosine_similarity(A_normalized, B_normalized)\n",
    "\n",
    "print(similarity)  # Output will reflect the cosine similarity of the normalized vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The cosine similarity ranges from -1 to 1, where:\n",
    "#1 indicates identical vectors (i.e., vectors point in the same direction).\n",
    "#0 indicates orthogonality (i.e., vectors are at a 90-degree angle to each other, no similarity).\n",
    "#-1 indicates opposite directions (i.e., vectors point in exactly opposite directions).\n",
    "#represents similarity between feature vectors, quantifying similarity between two vectors based on their direction, \n",
    "# irrespective of their magnitude.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Example Pandas Series\n",
    "s1 = pd.Series([1, 2, 3])\n",
    "s2 = pd.Series([4, 5, 6])\n",
    "\n",
    "# Reshape Series to 2D array (required by cosine_similarity)\n",
    "s1_reshaped = s1.values.reshape(1, -1)\n",
    "s2_reshaped = s2.values.reshape(1, -1)\n",
    "\n",
    "# Cosine Similarity Calculation\n",
    "cosine_sim = cosine_similarity(s1_reshaped, s2_reshaped)\n",
    "cosine_sim\n",
    "#print(f'Cosine Similarity: {cosine_sim[0][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarities = []\n",
    "for adj_A in list(.values()):\n",
    "    avg_embedding_A = average_embedding(get_embeddings(adj_A))\n",
    "    for adj_B in list(d_s.values()):\n",
    "        avg_embedding_B = average_embedding(get_embeddings(adj_B))\n",
    "        similarity_score = cosine_similarity([avg_embedding_A], [avg_embedding_B])[0][0]\n",
    "        similarities.append((adj_A, adj_B, similarity_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a method\n",
    "#embedding dimension is emotions\n",
    "#talk about options\n",
    "#get the brands, go through 50 emotins at a time\n",
    "#cosine: normalize first: l2 norm = 1\n",
    "#give instructions on readme on where key goes \n",
    "#first have everything in pandas df, then think about database\n",
    "# one module or package w 1 .py \n",
    "#adaptors that take in pydantic datatypes and will make into sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
