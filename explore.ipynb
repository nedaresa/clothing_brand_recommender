{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import sqlite3\n",
    "from itertools import islice\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "#!pip install openai -U\n",
    "from openai import OpenAI\n",
    "key=os.environ.get('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=key)\n",
    "model = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get human emotions    \n",
    " \n",
    "# Define the Pydantic model for the API response\n",
    "class EmotionsResponse(BaseModel):\n",
    "    Characteristics: List[str] = Field(None, description=\"List of non-redundant human emotions.\")\n",
    "\n",
    "def get_emotions(model: str) -> List[str]:\n",
    "    \"\"\"Gets a list of 50 unique and non-redundant human emotions using the specified gpt model.\"\"\"\n",
    "    \n",
    "    # Define system and user prompts\n",
    "    system_prompt = \"Find 50 different, exclusive and unique human emotions. \"\\\n",
    "    \"For example, pick joy or happiness, pick Shame or Embarrassment, pick Envy or Jealousy, \"\\\n",
    "    \"pick Hate or disgust or hatered or Resentment. \"\\\n",
    "\n",
    "    user_prompt = \"Select 50 different and unique human emotions.\"\n",
    "\n",
    "    try:\n",
    "        #Call the API to get the completion\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model= model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Be a helpful assistant.\"},\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"system\", \"content\": \"make sure to include either joy or happiness, not both.\"},\n",
    "                {\"role\": \"system\", \"content\": \"make sure to include either Shame or Embarrassment, not both\"},\n",
    "                {\"role\": \"system\", \"content\": \"make sure to include either Envy or Jealousy, not both\"},\n",
    "                {\"role\": \"system\", \"content\": \"make sure to include either Hate or disgust or hatered or Resentment\"},\n",
    "                {\"role\": \"system\", \"content\": \"Check again to remove redundant emotions. I only want unique emotions.\"},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            response_format=EmotionsResponse\n",
    "        )\n",
    "\n",
    "        #output returns in the defined pydantic style\n",
    "        output = completion.choices[0].message.parsed\n",
    "        return output.json()\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle exceptions such as API errors, etc\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return json.dumps({})\n",
    "\n",
    "# Example usage\n",
    "emotions = get_emotions(model= model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get 100 best selling American clothing brands \n",
    "\n",
    "# Define the Pydantic model for the API response\n",
    "class BrandsResponse(BaseModel):\n",
    "    Brands: List[str] = Field(None, description=\"Brands as a list of strings.\")\n",
    "\n",
    "def get_brands(model: str) -> List[str]:\n",
    "    \"\"\"Get 100 best selling American clothing brands using the specified gpt model.\"\"\"\n",
    "\n",
    "    try:\n",
    "        #Call the API to get the completion\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model= model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Be a helpful assistant.\"},\n",
    "                {\"role\": \"system\", \"content\": \"Find 100 non-redundant best selling American clothing brands.\"},\n",
    "                {\"role\": \"system\", \"content\": \"DONT MAKE ANY MISTAKES, check if you did any.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Give me 100 best selling American clothing brands.\"}\n",
    "            ],\n",
    "            response_format=BrandsResponse\n",
    "        )\n",
    "\n",
    "        #output returns in the defined pydantic style\n",
    "        output = completion.choices[0].message.parsed\n",
    "        return output.json()\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle exceptions such as API errors, etc\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return json.dumps({})\n",
    "\n",
    "# Example usage\n",
    "brands = get_brands(model= model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Brands\": [\"Levi\\'s\", \"Ralph Lauren\", \"Nike\", \"Tommy Hilfiger\", \"Calvin Klein\", \"Under Armour\", \"Hanes\", \"Columbia\", \"Carhartt\", \"Polo Ralph Lauren\", \"GAP\", \"Old Navy\", \"Michael Kors\", \"Coach\", \"Vans\", \"Converse\", \"North Face\", \"Patagonia\", \"Abercrombie & Fitch\", \"American Eagle Outfitters\", \"Brooks Brothers\", \"Kate Spade\", \"Vera Bradley\", \"Wrangler\", \"Dockers\", \"Hollister\", \"A\\\\u00e9ropostale\", \"L.L. Bean\", \"J.Crew\", \"Lacoste\", \"Express\", \"Banana Republic\", \"Forever 21\", \"Victoria\\'s Secret\", \"Guess\", \"Lululemon\", \"New Balance\", \"Champion\", \"Fila\", \"Eddie Bauer\", \"Urban Outfitters\", \"Lucky Brand\", \"Anthropologie\", \"Free People\", \"Tory Burch\", \"Skechers\", \"Steve Madden\", \"Cole Haan\", \"Marc Jacobs\", \"Stuart Weitzman\", \"Joe\\'s Jeans\", \"True Religion\", \"Carter\\'s\", \"Gap Kids\", \"Justice\", \"Athleta\", \"ALDO\", \"PacSun\", \"G-Star RAW\", \"Keds\", \"Reebok\", \"Crocs\", \"Aldo\", \"Rockport\", \"American Apparel\", \"Ann Taylor\", \"Lane Bryant\", \"Leggs\", \"Lee\", \"Izod\", \"Pendleton\", \"Orvis\", \"Ted Baker\", \"Jennifer Lopez Collection\", \"Nine West\", \"Timberland\", \"Massimo Dutti\", \"DKNY\", \"Kenneth Cole\", \"Roxy\", \"Billabong\", \"Hurley\", \"Volcom\", \"Ugg\", \"Dockers\", \"Dockers\", \"New York & Company\", \"Quiksilver\", \"Fila\", \"Timberland\", \"Marmot\", \"Hush Puppies\", \"Puma\", \"Jos. A. Bank\", \"Perry Ellis\", \"Nautica\", \"Under Armour\", \"Hugo Boss\", \"Big Dog Sportswear\", \"Dickies\", \"Jansport\", \"Fruit of the Loom\"]}'"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_ls = list(json.loads(emotions).values())[0]\n",
    "brands_ls = list(json.loads(brands).values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding brand in emotions space: Get association scores between an input and list of emotions\n",
    "\n",
    "Characteristic = Enum('Characteristic', dict([(emotion, emotion) for emotion in emotions_ls]))\n",
    "\n",
    "class EmotionalAssociationScore(BaseModel):\n",
    "    emotion: Characteristic\n",
    "    score: float\n",
    "\n",
    "class EmotionalAssociationScores(BaseModel):\n",
    "    associations: List[EmotionalAssociationScore] = Field(description=\"A list of emotions and associated scores\")\n",
    "\n",
    "def emotional_association_scores(\n",
    "        thing, \n",
    "        model,\n",
    "        emotions\n",
    "    ):\n",
    "    \n",
    "    prompt = f\"Assign emotional association scores between {0} and {len(emotions)} for the provided thing. \"\\\n",
    "    \"Assign a score for each of the following emotions. Briefly, explain the reason behind the association score.\"\\\n",
    "    \"Ensure the scores reflect the association strength for the specified thing. \"\\\n",
    "    \"Thing: \"\\\n",
    "    f\"{thing}\"\n",
    "            \n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model = model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Be a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=EmotionalAssociationScores,\n",
    "    )\n",
    "    #output returns in the defined pydantic style\n",
    "    output = completion.choices[0].message.parsed\n",
    "    return thing, output.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('summer',\n",
       " '{\"associations\": [{\"emotion\": \"Joy\", \"score\": 2.0}, {\"emotion\": \"Shame\", \"score\": 0.0}, {\"emotion\": \"Envy\", \"score\": 0.5}, {\"emotion\": \"Resentment\", \"score\": 0.2}, {\"emotion\": \"Surprise\", \"score\": 0.5}, {\"emotion\": \"Fear\", \"score\": 0.2}, {\"emotion\": \"Sadness\", \"score\": 0.3}, {\"emotion\": \"Anger\", \"score\": 0.1}, {\"emotion\": \"Love\", \"score\": 2.0}, {\"emotion\": \"Hope\", \"score\": 1.5}, {\"emotion\": \"Pride\", \"score\": 0.5}, {\"emotion\": \"Gratitude\", \"score\": 1.0}, {\"emotion\": \"Curiosity\", \"score\": 0.8}, {\"emotion\": \"Anxiety\", \"score\": 0.4}, {\"emotion\": \"Contentment\", \"score\": 1.5}, {\"emotion\": \"Confusion\", \"score\": 0.2}, {\"emotion\": \"Boredom\", \"score\": 0.3}, {\"emotion\": \"Disappointment\", \"score\": 0.2}, {\"emotion\": \"Ecstasy\", \"score\": 1.2}, {\"emotion\": \"Empathy\", \"score\": 0.3}, {\"emotion\": \"Nostalgia\", \"score\": 1.5}, {\"emotion\": \"Loneliness\", \"score\": 0.5}, {\"emotion\": \"Regret\", \"score\": 0.2}, {\"emotion\": \"Guilt\", \"score\": 0.1}, {\"emotion\": \"Admiration\", \"score\": 0.7}, {\"emotion\": \"Anticipation\", \"score\": 1.8}, {\"emotion\": \"Awe\", \"score\": 1.0}, {\"emotion\": \"Frustration\", \"score\": 0.6}, {\"emotion\": \"Courage\", \"score\": 0.5}, {\"emotion\": \"Skepticism\", \"score\": 0.2}, {\"emotion\": \"Insecurity\", \"score\": 0.3}, {\"emotion\": \"Desperation\", \"score\": 0.1}, {\"emotion\": \"Relief\", \"score\": 1.0}, {\"emotion\": \"Peacefulness\", \"score\": 1.8}, {\"emotion\": \"Melancholy\", \"score\": 0.5}, {\"emotion\": \"Disgust\", \"score\": 0.1}, {\"emotion\": \"Trust\", \"score\": 0.7}, {\"emotion\": \"Resilience\", \"score\": 0.6}, {\"emotion\": \"Desire\", \"score\": 1.2}, {\"emotion\": \"Dread\", \"score\": 0.2}, {\"emotion\": \"Elation\", \"score\": 1.5}, {\"emotion\": \"Compassion\", \"score\": 0.4}, {\"emotion\": \"Vindication\", \"score\": 0.1}, {\"emotion\": \"Impatience\", \"score\": 0.3}, {\"emotion\": \"Sorrow\", \"score\": 0.1}, {\"emotion\": \"Euphoria\", \"score\": 1.3}, {\"emotion\": \"Contempt\", \"score\": 0.1}, {\"emotion\": \"Humiliation\", \"score\": 0.1}, {\"emotion\": \"Terror\", \"score\": 0.1}]}')"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotional_association_scores(\n",
    "        thing, \n",
    "        model,\n",
    "        emotions[:2]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not using this for the moment\n",
    "# #Embedding brands in emotions space: \n",
    "# # tried nested prompt but decided to go with one prompt and a list comprehension\n",
    "# emotions= emotions_ls\n",
    "# associations_brands = [emotional_association_scores(thing, model, emotions) for thing in brands_ls[:3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(thing, model, emotions):\n",
    "    gpt = emotional_association_scores(thing, model, emotions)\n",
    "    data = list(json.loads(gpt[1]).values())[0]\n",
    "    df = pd.DataFrame(data)\n",
    "    df.rename(columns = {'score': gpt[0]}, inplace=True)\n",
    "    df.set_index('emotion', inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_dfs(things_ls, model, emotions):\n",
    "    merged_df = pd.DataFrame()\n",
    "    for thing in things_ls:\n",
    "        new_df = get_df(thing, model, emotions)\n",
    "        if merged_df.empty:\n",
    "            merged_df = new_df\n",
    "        else:\n",
    "            merged_df = pd.merge(merged_df, new_df, left_index=True, right_index=True, how='outer')\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "things_ls = brands_ls\n",
    "dfs = get_dfs(things_ls, model, emotions)\n",
    "# Drop columns with NaN values\n",
    "dfs_cleaned = dfs.dropna(axis=1)\n",
    "\n",
    "dfs_cleaned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set pandas to display all rows and columns\n",
    "# pd.set_option('display.max_rows', None)  # Show all rows\n",
    "# pd.set_option('display.max_columns', None)  # Show all columns\n",
    "# pd.set_option('display.width', None)  # Adjust display width to prevent column cutting\n",
    "# pd.set_option('display.max_colwidth', None)  # Show full content in columns\n",
    "# dfs.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Confirmed no need to l2 norm vectors for sklearn's cosine similarity:\n",
    "# # Define your original vectors\n",
    "# A = np.array([[2, 3]])\n",
    "# B = np.array([[5, 4]])\n",
    "\n",
    "# # Calculate cosine similarity without normalization\n",
    "# cosine_sim_without_norm = cosine_similarity(A, B)\n",
    "\n",
    "# # L2 normalize the vectors\n",
    "# A_normalized = A / np.linalg.norm(A)\n",
    "# B_normalized = B / np.linalg.norm(B)\n",
    "\n",
    "# # Calculate cosine similarity with normalization\n",
    "# cosine_sim_with_norm = cosine_similarity(A_normalized, B_normalized)\n",
    "\n",
    "# # Print the outputs\n",
    "# print(\"Cosine Similarity without normalization:\")\n",
    "# print(cosine_sim_without_norm[0][0])  # Output from unnormalized vectors\n",
    "\n",
    "# print(\"\\nCosine Similarity with normalization:\")\n",
    "# print(cosine_sim_with_norm[0][0])      # Output from normalized vectors\n",
    "# cosine_sim_without_norm[0][0]==cosine_sim_with_norm[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_similarity(df, dfs):\n",
    "    similarities = dict()\n",
    "\n",
    "    # Reshape Series to 2D array (required by cosine_similarity)\n",
    "    s1 = df.values.reshape(1, -1)\n",
    "\n",
    "    for col in list(dfs.columns):\n",
    "        # Reshape\n",
    "        s2= dfs[col].values.reshape(1, -1)\n",
    "\n",
    "        cosine_sim = cosine_similarity(s1, s2)\n",
    "        similarities[col]= cosine_sim[0][0]\n",
    "\n",
    "    sorted_dict = dict(sorted(similarities.items(), key=lambda item: item[1], reverse = True))\n",
    "\n",
    "    # Get the top 3 (highest similarity)\n",
    "    top_3 = list(dict(islice(sorted_dict.items(), 3)).keys())\n",
    "\n",
    "    return top_3\n",
    "\n",
    "get_similarity(df, dfs_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The cosine similarity ranges from -1 to 1, where:\n",
    "#1 indicates identical vectors (i.e., vectors point in the same direction).\n",
    "#0 indicates orthogonality (i.e., vectors are at a 90-degree angle to each other, no similarity).\n",
    "#-1 indicates opposite directions (i.e., vectors point in exactly opposite directions).\n",
    "#represents similarity between feature vectors, quantifying similarity between two vectors based on their direction, \n",
    "# irrespective of their magnitude.\n",
    "\n",
    "#embeddings happen in a much smaller space of emotions as oppossed to ordinary, more common embeddings in a large space as more commonly done with openai api (read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a method\n",
    "#embedding dimension is emotions\n",
    "#talk about options\n",
    "#get the brands, go through 50 emotins at a time\n",
    "#cosine: normalize first: l2 norm = 1\n",
    "#give instructions on readme on where key goes \n",
    "#first have everything in pandas df, then think about database\n",
    "# one module or package w 1 .py \n",
    "#adaptors that take in pydantic datatypes and will make into sql\n",
    "#argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to check emotion redundancy by looking at example groups \n",
    "#[i for i in list(json.loads(emotions).values())[0] if i in ['Joy', 'Happiness', 'Shame', 'Embarrassment', 'Envy', 'Jealousy' , 'Hate', 'disgust', 'hatered', 'Resentment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test0\n",
    "\n",
    "#Retrieve emotions from datbase or through openAI API\n",
    "# if os.path.exists('emotions.json'):\n",
    "#     with open('emotions.json', 'r') as f:\n",
    "#         emotions_json = json.load(f)\n",
    "# else:\n",
    "#     emotions_json = get_emotions(model, api_key)\n",
    "\n",
    "#test sqlite\n",
    "# with sqlite3.connect(os.path.abspath('database.db')) as conn:\n",
    "#     # Write the DataFrame to the database\n",
    "#     df.to_sql('mytable', conn, if_exists='replace', index=False)\n",
    "#     #cursor = conn.cursor()\n",
    "#     #cursor.execute('SELECT SQLITE_VERSION()')\n",
    "#     #data = cursor.fetchone()\n",
    "#     #print('SQLite version:', data)\n",
    "\n",
    "# query = \"SELECT * FROM mytable\"\n",
    "# with sqlite3.connect(os.path.abspath('database.db')) as conn:\n",
    "#     df_test= pd.read_sql_query(query, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test0\n",
    "#test\n",
    "\n",
    "class EmotionsResponse(BaseModel):\n",
    "    #None as default if value not provided\n",
    "    Emotions: List[str] = Field(None, description=\"List of non-redundant human emotions.\") \n",
    "\n",
    "def get_emotions(model: str, api_key: str) -> List[str]:\n",
    "    \"\"\"Gets a list of 50 unique and non-redundant human emotions using the specified gpt model.\"\"\"\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    system_prompt = \"Find 50 different, exclusive and unique human emotions. \"\\\n",
    "    \"For example, pick joy or happiness, pick Shame or Embarrassment, pick Envy or Jealousy, \"\\\n",
    "    \"pick Hate or disgust or hatered or Resentment. \"\\\n",
    "\n",
    "    user_prompt = \"Select 50 different and unique human emotions.\"\n",
    "\n",
    "    try:\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model= model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            response_format=EmotionsResponse\n",
    "        )\n",
    "\n",
    "        #output in the defined pydantic style\n",
    "        output = completion.choices[0].message.parsed\n",
    "        return output.json()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return json.dumps({})\n",
    "\n",
    "def get_emotions_df(model, api_key):\n",
    "    emotions_json = get_emotions(model, api_key)\n",
    "    emotions = list(json.loads(emotions_json).values())[0]\n",
    "    emotions_df = pd.DataFrame(emotions, columns = ['emotion'])\n",
    "    emotions_df['emotion_id'] = emotions_df.index\n",
    "    emotions_df = emotions_df[['emotion_id','emotion']]\n",
    "    return emotions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_df = get_emotions_df(model, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test1\n",
    "#Get 100 best selling American clothing brands using the Pydantic model for the API response\n",
    "class BrandResponse(BaseModel):\n",
    "    name: str = Field(description=\"brand name as a string.\")\n",
    "    brand_info: str = Field(description=\"Brand information as a string.\")\n",
    "class BrandsResponse(BaseModel):\n",
    "    brands: List[BrandResponse] = Field(description=\"A list of names and information.\")\n",
    "\n",
    "def get_brands(model: str, api_key: str) -> List[str]:\n",
    "    \"\"\"Get 5 best selling American clothing brands using the specified gpt model. Provide a brief information about each brand.\"\"\"\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    try:\n",
    "        #Call the API to get the completion\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model= model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Find 5 non-redundant best selling American clothing brands.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Give me 5 best selling American clothing brands and a brief information about each brand.\"}\n",
    "            ],\n",
    "            response_format=BrandsResponse\n",
    "        )\n",
    "        #output in the defined pydantic style\n",
    "        output = completion.choices[0].message.parsed\n",
    "\n",
    "        return output.json()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return json.dumps({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_brands = get_brands(model, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"brands\": [{\"name\": \"Nike\", \"brand_info\": \"Founded in 1964, Nike is a global leader in sportswear and athletic shoes. The brand is widely recognized for its innovative designs and performance-enhancing technologies.\"}, {\"name\": \"Ralph Lauren\", \"brand_info\": \"Established in 1967 by Ralph Lauren, this brand is synonymous with timeless American style, offering a wide range of products from apparel to home furnishings, known for its iconic Polo shirts.\"}, {\"name\": \"Levi\\'s\", \"brand_info\": \"Dating back to 1853, Levi\\'s is renowned for its durable and stylish denim products. The brand is most famous for creating the quintessential American blue jeans.\"}, {\"name\": \"Tommy Hilfiger\", \"brand_info\": \"Founded in 1985, Tommy Hilfiger is celebrated for its classic American preppy style with a modern twist, offering high-quality garments often characterized by the brand\\'s signature red, white, and blue logo.\"}, {\"name\": \"Calvin Klein\", \"brand_info\": \"Since its inception in 1968, Calvin Klein has been famed for its minimalist and provocative designs, particularly in underwear and fragrances, setting trends in the fashion industry.\"}]}'"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test2\n",
    "# Embedding and getting association scores between an input and list of emotions\n",
    "\n",
    "def emotional_association_scores(\n",
    "        thing, \n",
    "        model,\n",
    "        emotions, api_key\n",
    "    ):\n",
    " \n",
    "    Characteristic = Enum('Characteristic', dict([(emotion, emotion) for emotion in emotions]))\n",
    "\n",
    "    class EmotionalAssociationScore(BaseModel):\n",
    "        emotion: Characteristic\n",
    "        score: float\n",
    "\n",
    "    class EmotionalAssociationScores(BaseModel):\n",
    "        associations: List[EmotionalAssociationScore] = Field(description=\"List of dictionaries e.g. [{'emotion':'sadness', 'score': 4.0}]\")\n",
    "        explanation: str = Field(description=\"String explaining the association scores.\")\n",
    "    \n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    prompt = f\"Assign emotional association scores between {0} and {len(emotions)} for the provided thing. \"\\\n",
    "    \"Assign a score for each of the given emotions. Briefly explain the reason behind the association scores.\"\\\n",
    "    \"Ensure the scores reflect the association strength for the specified thing. \"\\\n",
    "    \"Thing: \"\\\n",
    "    f\"{thing}\"\n",
    "            \n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model = model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Be a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=EmotionalAssociationScores,\n",
    "    )\n",
    "    #output in the defined pydantic style\n",
    "    output = completion.choices[0].message.parsed\n",
    "    return output.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('summer',\n",
       " '{\"associations\": [{\"emotion\": \"Joy\", \"score\": 1.8}, {\"emotion\": \"Sadness\", \"score\": 0.2}], \"explanation\": \"Summer is often associated with joy due to the warm weather, holidays, and outdoor activities such as going to the beach, barbecues, and vacations, which are typically enjoyable experiences, hence a high score for Joy. It receives a lower score for Sadness as people may associate summer with the end of the academic year where friends part ways, or the discomfort of very high temperatures.\"}')"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thing ='summer'\n",
    "api_key=key\n",
    "emotions_df = get_emotions_df(model, api_key)\n",
    "emotions = list(emotions_df['emotion'].values)\n",
    "out = emotional_association_scores(thing, model, emotions[:2], api_key)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Envy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion_id  emotion\n",
       "0           0      Joy\n",
       "1           1    Shame\n",
       "2           2     Envy\n",
       "3           3     Hate\n",
       "4           4  Anxiety"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"associations\": [{\"emotion\": \"Joy\", \"score\": 1.5}, {\"emotion\": \"Sadness\", \"score\": 0.5}], \"explanation\": \"Summer often brings joy to many people due to the warm weather, the possibility of beach vacations, outdoor activities, holidays, and other cheerful events usually associated with this season, so the score for joy is relatively high at 1.5. However, it can also evoke sadness for some because it marks the end of school for certain grades or universities, separation from friends or classmates during the summer break, or because the heat can be unpleasant, which gives it a lower sadness score of 0.5.\"}'"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = emotional_association_scores(thing, model, emotions[:2], api_key)\n",
    "gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test get_df\n",
    "def get_one(thing, model, emotions_df, api_key):\n",
    "    emotions = list(emotions_df['emotion'].values)\n",
    "    gpt = emotional_association_scores(thing, model, emotions, api_key)\n",
    "    scoresinfo = json.loads(gpt)['explanation']\n",
    "    \n",
    "    df = pd.DataFrame(json.loads(gpt)['associations'])\n",
    "    df.rename(columns = {'score': thing}, inplace=True)\n",
    "    df = pd.merge(df, emotions_df, on ='emotion', how ='inner')\n",
    "    df.drop('emotion', axis = 1, inplace=True)\n",
    "    df= df[['emotion_id',f'{thing}']]\n",
    "    return ({thing: scoresinfo}, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_one = get_one(thing, model, emotions_df.iloc[:2], api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'summer': 'Summer is a season typically associated with positive experiences such as vacations, warm weather, and outdoor activities, which is why it scores high in joy, with a score close to 2. It is usually a time when people feel happy and relaxed. In contrast, summer is not usually associated with shame, as it does not inherently involve aspects that would cause embarrassment or disgrace. Therefore, it receives a low score of 0.2 for shame, given that such associations might only occur in specific and less common contexts.'},\n",
       "    emotion_id  summer\n",
       " 0           0     1.8\n",
       " 1           1     0.2)"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "def get_all(brands_df, model, emotions_df, api_key):\n",
    "    scoresinfo = []\n",
    "    merged_df = pd.DataFrame()\n",
    "    brands = brands_df['name']\n",
    "    for brand in brands:\n",
    "        out = get_one(brand, model, emotions_df, api_key)\n",
    "        scoresinfo.append(out[0])\n",
    "        new_df = out[1]\n",
    "        if merged_df.empty:\n",
    "            merged_df = new_df\n",
    "        else:\n",
    "            merged_df = pd.merge(merged_df, new_df, on='emotion_id', how='inner')\n",
    "    return (scoresinfo, merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'Nike': \"Nike, being a major sportswear and athletic company, is often associated with joy due to the excitement and positive feelings associated with sports, fitness, and achievement. This accounts for a higher score of 1.5 in joy. On the other hand, Nike has faced several controversies related to labor practices and allegations of sweatshop conditions, which contribute to a sense of shame for some consumers. However, these controversies might not be as prominent in the daily consumer's perception compared to the positive aspects, resulting in a lower score of 0.5 in shame.\"},\n",
       "  {'Ralph Lauren': 'Ralph Lauren often evokes a sense of joy because of its association with high-end fashion, elegance, and a feeling of luxury that can bring pleasure and satisfaction to people. Hence, it scores a 1.5 for joy, reflecting this positive emotional connection without necessarily being extremely strong for everyone. On the other hand, Ralph Lauren generally does not evoke feelings of shame. While there may be rare instances or associations where luxury fashion can lead to feelings of inadequacy or shame due to high costs or social status implications, these instances are significantly less common, leading to a score of 0.2 for shame.'},\n",
       "  {\"Levi's\": \"Levi's, being a popular and trusted brand of clothing, particularly known for its jeans, is often associated with joy due to the satisfaction customers feel when wearing a well-fitting and stylish pair of jeans. This strong brand reputation and the positive experiences of wearing Levi's contribute to a relatively high score of 1.5 for Joy. On the other hand, the emotion of Shame is less commonly associated with Levi's, as they are generally viewed positively. However, there could be a slight association due to issues some might feel related to the brand's high price, or if social pressures around fashion choices arise. Therefore, the score for Shame is relatively low, at 0.5.\"}],\n",
       "    emotion_id  Nike  Ralph Lauren  Levi's\n",
       " 0           0   1.5           1.5     1.5\n",
       " 1           1   0.5           0.2     0.5)"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands_df = pd.DataFrame(list(json.loads(get_brands(model, api_key)).values())[0])\n",
    "brands_df.reset_index(inplace= True)\n",
    "brands_df.rename({'index':'brand_id'}, axis = 1, inplace = True)\n",
    "brands_df['gpt'] = model\n",
    "get_all(brands_df.iloc[:3], model, emotions_df.iloc[:2], api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "def get_brands_scores(model, api_key, emotions_df):\n",
    "    out = json.loads(get_brands(model, api_key))\n",
    "    brands_df = pd.DataFrame(list(out.values())[0])\n",
    "    brands_df.reset_index(inplace= True)\n",
    "    brands_df.rename({'index':'brand_id'}, axis = 1, inplace = True)\n",
    "    brands_df['gpt'] = model\n",
    "\n",
    "    all = get_all(brands_df, model, emotions_df, api_key)\n",
    "    scoresinfo= all[0]\n",
    "    scores_df = all[1]\n",
    "    scores_df = pd.melt(scores_df, id_vars='emotion_id', value_vars =list(scores_df.columns))\n",
    "    scores_df.rename(columns = {'variable':'name','value':'score'}, inplace=True)\n",
    "    scores_df = pd.merge(scores_df, brands_df[['brand_id','name']], on ='name', how ='inner')\n",
    "    scores_df.drop('name', axis= 1, inplace=True)\n",
    "    scores_df = scores_df[['emotion_id','brand_id','score']]\n",
    "\n",
    "    scoreinfo_df= pd.DataFrame([(k,v) for data in scoresinfo for k,v in data.items()], columns = ['name', 'scores_info'])\n",
    "    brands_df = pd.merge(brands_df, scoreinfo_df, how = 'left', on ='name' )\n",
    "    brands_df = brands_df[['brand_id','name','brand_info', 'scores_info','gpt']]\n",
    "    return (brands_df, scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = get_brands_scores(model, api_key, emotions_df[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_id</th>\n",
       "      <th>name</th>\n",
       "      <th>brand_info</th>\n",
       "      <th>scores_info</th>\n",
       "      <th>gpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Founded in 1964 and based in Oregon, Nike is a...</td>\n",
       "      <td>Nike is a popular athletic brand associated wi...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ralph Lauren</td>\n",
       "      <td>Ralph Lauren, established in 1967, is a symbol...</td>\n",
       "      <td>For 'Joy', the score is 2.5 because Ralph Laur...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Under Armour</td>\n",
       "      <td>Under Armour, headquartered in Baltimore since...</td>\n",
       "      <td>For the brand Under Armour, the emotion of 'Jo...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Levi's</td>\n",
       "      <td>Levi's, originating in San Francisco and found...</td>\n",
       "      <td>Levi's is a well-known and respected brand, pa...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Tommy Hilfiger, an influential brand since 198...</td>\n",
       "      <td>Tommy Hilfiger is a well-known fashion brand t...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand_id            name  \\\n",
       "0         0            Nike   \n",
       "1         1    Ralph Lauren   \n",
       "2         2    Under Armour   \n",
       "3         3          Levi's   \n",
       "4         4  Tommy Hilfiger   \n",
       "\n",
       "                                          brand_info  \\\n",
       "0  Founded in 1964 and based in Oregon, Nike is a...   \n",
       "1  Ralph Lauren, established in 1967, is a symbol...   \n",
       "2  Under Armour, headquartered in Baltimore since...   \n",
       "3  Levi's, originating in San Francisco and found...   \n",
       "4  Tommy Hilfiger, an influential brand since 198...   \n",
       "\n",
       "                                         scores_info                gpt  \n",
       "0  Nike is a popular athletic brand associated wi...  gpt-4o-2024-08-06  \n",
       "1  For 'Joy', the score is 2.5 because Ralph Laur...  gpt-4o-2024-08-06  \n",
       "2  For the brand Under Armour, the emotion of 'Jo...  gpt-4o-2024-08-06  \n",
       "3  Levi's is a well-known and respected brand, pa...  gpt-4o-2024-08-06  \n",
       "4  Tommy Hilfiger is a well-known fashion brand t...  gpt-4o-2024-08-06  "
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nike': 0,\n",
       " 'Ralph Lauren': 1,\n",
       " \"Levi's\": 2,\n",
       " 'Under Armour': 3,\n",
       " 'Calvin Klein': 4}"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_id</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion_id  brand_id  score\n",
       "0           0         0    1.8\n",
       "1           1         0    0.2\n",
       "2           0         1    1.7\n",
       "3           1         1    0.3\n",
       "4           0         2    1.7\n",
       "5           1         2    0.3\n",
       "6           0         3    1.8\n",
       "7           1         3    0.5\n",
       "8           0         4    1.5\n",
       "9           1         4    0.5"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.8\n",
       "1    0.2\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_id_ls = list(bs[1]['brand_id'].unique())\n",
    "bs[1].loc[bs[1]['brand_id']==0]['score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "def get_similarity(df, dfs, brands_df, number):\n",
    "    similarities = dict()\n",
    "\n",
    "    df.sort_values(by='emotion_id',inplace=True)\n",
    "    df.set_index('emotion_id', inplace=True)\n",
    "    # Reshape Series to 2D array (required by cosine_similarity)\n",
    "    s1 = df.values.reshape(1, -1)\n",
    "\n",
    "    brand_id_ls = list(dfs['brand_id'].unique())\n",
    "    for brand_id in brand_id_ls:\n",
    "        df_brand = dfs.loc[dfs['brand_id']==brand_id]\n",
    "        df_brand = df_brand.sort_values(by='emotion_id')\n",
    "        df_brand= df_brand.set_index('emotion_id')\n",
    "        s2= df_brand['score'].values.reshape(1, -1)\n",
    "        cosine_sim = cosine_similarity(s1, s2)\n",
    "        similarities[brand_id]= cosine_sim[0][0]\n",
    "        \n",
    "    name_id = dict(zip(brands_df['name'], brands_df['brand_id']))\n",
    "    similarities = {k: similarities[v] for k, v in name_id.items() if v in similarities}\n",
    "    sorted_s = sorted(similarities.items(), key=lambda item: item[1], reverse = True)\n",
    "    recommendations = list(dict(sorted_s[:number]).keys())\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Nike': 0, \"Levi's\": 1, 'Ralph Lauren': 2, 'Under Armour': 3, 'Calvin Klein': 4}\n",
      "{'Nike': 0.9782838736655737, \"Levi's\": 0.9968895725584536, 'Ralph Lauren': 0.9782838736655737, 'Under Armour': 0.9670913609804875, 'Calvin Klein': 0.9011533136409089}\n",
      "[(\"Levi's\", 0.9968895725584536), ('Nike', 0.9782838736655737), ('Ralph Lauren', 0.9782838736655737), ('Under Armour', 0.9670913609804875), ('Calvin Klein', 0.9011533136409089)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Levi's\", 'Nike']"
      ]
     },
     "execution_count": 822,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number = 2\n",
    "bs = get_brands_scores(model, api_key, emotions_df[:3])\n",
    "out_one = get_one(thing, model, emotions_df.iloc[:3], api_key)\n",
    "get_similarity(out_one[1], bs[1], bs[0], number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_emotions_exists(model, api_key, db_name, mytable):\n",
    "#     with sqlite3.connect(os.path.abspath(db_name)) as conn:\n",
    "#         cursor = conn.cursor()\n",
    "#         cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name=?\", (mytable,))\n",
    "#         if cursor.fetchone() is not None:\n",
    "#             print(f'Reading {mytable} from database...')\n",
    "#             query = f'SELECT * FROM {mytable}' \n",
    "#             df = pd.read_sql_query(query, conn)\n",
    "#         else:\n",
    "#             print(f\"{mytable} doesn't exist so generating one...\")\n",
    "            \n",
    "#     return df\n",
    "\n",
    "def check_data_exists(model, api_key, db_name, update_brand_list):\n",
    "    with sqlite3.connect(os.path.abspath(db_name)) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name in ('emotions', 'brands', 'association_scores')\")\n",
    "        tables = cursor.fetchall()\n",
    "        if len(tables) == 3:\n",
    "            query = \"SELECT * FROM 'emotions'\"\n",
    "            emotions_df = pd.read_sql_query(query, conn) \n",
    "\n",
    "            if update_brand_list == 'no':\n",
    "                print('Reading from database...')\n",
    "                query = \"SELECT * FROM 'association_scores'\" \n",
    "                scores_df = pd.read_sql_query(query, conn)\n",
    "            else:\n",
    "                print('Generating brands data...')\n",
    "                brands, scores_df = get_brands_scores(model, api_key, emotions_df['emotion'][:3])\n",
    "                brands.to_sql('brands', conn, if_exists = 'replace', index=False)\n",
    "                scores_df.to_sql('association_scores', conn, if_exists = 'replace', index=False)\n",
    "\n",
    "        else:\n",
    "            print(\"Brands data doesn't exist so generating...\")\n",
    "            emotions_df = get_emotions_df(model, api_key)\n",
    "            emotions_df.to_sql('emotions', conn, if_exists = 'replace', index=False)\n",
    "\n",
    "            brands, scores_df = get_brands_scores(model, api_key, emotions_df['emotion'][:3])\n",
    "            brands.to_sql('brands', conn, if_exists = 'replace', index=False)\n",
    "            scores_df.to_sql('association_scores', conn, if_exists = 'replace', index=False)\n",
    "\n",
    "    return (emotions_df, scores_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "model = \"gpt-4o-2024-08-06\"\n",
    "api_key=os.environ.get('OPENAI_API_KEY')\n",
    "db_name = 'database.db'\n",
    "update_brand_list = 'no'\n",
    "number = 3\n",
    "thing ='summer'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nike</th>\n",
       "      <th>Levi's</th>\n",
       "      <th>Ralph Lauren</th>\n",
       "      <th>Under Armour</th>\n",
       "      <th>Calvin Klein</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Joy</th>\n",
       "      <td>45.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sadness</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anger</th>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fear</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surprise</th>\n",
       "      <td>35.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disgust</th>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trust</th>\n",
       "      <td>40.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anticipation</th>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shame</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Envy</th>\n",
       "      <td>28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jealousy</th>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Love</th>\n",
       "      <td>42.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Awe</th>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contempt</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regret</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Excitement</th>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apprehension</th>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Curiosity</th>\n",
       "      <td>25.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gratitude</th>\n",
       "      <td>15.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guilt</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boredom</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loneliness</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longing</th>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Confusion</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Empathy</th>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hope</th>\n",
       "      <td>25.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nostalgia</th>\n",
       "      <td>22.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relief</th>\n",
       "      <td>20.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Desperation</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insecurity</th>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pride</th>\n",
       "      <td>45.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Satisfaction</th>\n",
       "      <td>38.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sympathy</th>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disappointment</th>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resentment</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarrassment</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delight</th>\n",
       "      <td>40.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Courage</th>\n",
       "      <td>35.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frustration</th>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pessimism</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Desire</th>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fascination</th>\n",
       "      <td>27.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Optimism</th>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Compassion</th>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melancholy</th>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shock</th>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vindication</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suspicion</th>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serenity</th>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Nike  Levi's  Ralph Lauren  Under Armour  Calvin Klein\n",
       "emotion                                                               \n",
       "Joy             45.0    40.0          40.0          35.0          40.0\n",
       "Sadness         10.0    10.0          10.0          10.0           5.0\n",
       "Anger           12.0     5.0           5.0           5.0          10.0\n",
       "Fear            15.0     8.0           8.0          15.0           8.0\n",
       "Surprise        35.0    25.0          15.0          20.0          20.0\n",
       "Disgust          8.0     5.0           3.0           5.0           5.0\n",
       "Trust           40.0    42.0          35.0          38.0          30.0\n",
       "Anticipation    30.0    30.0          30.0          30.0          35.0\n",
       "Shame           10.0     6.0           5.0           5.0           5.0\n",
       "Envy            28.0    20.0          25.0          18.0          25.0\n",
       "Jealousy        20.0    18.0          20.0          12.0          20.0\n",
       "Love            42.0    40.0          30.0          28.0          30.0\n",
       "Awe             32.0    15.0          20.0          22.0          15.0\n",
       "Contempt        10.0     3.0           2.0           5.0           5.0\n",
       "Regret           5.0    10.0           5.0           5.0           5.0\n",
       "Excitement      40.0    35.0          35.0          32.0          38.0\n",
       "Apprehension    12.0     8.0           5.0          10.0           8.0\n",
       "Curiosity       25.0    28.0          25.0          27.0          30.0\n",
       "Gratitude       15.0    32.0          12.0          25.0          25.0\n",
       "Guilt            8.0     4.0           4.0           5.0           5.0\n",
       "Boredom          5.0     7.0           3.0           8.0           5.0\n",
       "Loneliness       5.0     5.0           5.0           5.0           5.0\n",
       "Longing         18.0    15.0          15.0          10.0          10.0\n",
       "Confusion       10.0    10.0          10.0          10.0          10.0\n",
       "Empathy         15.0    12.0           8.0           8.0          10.0\n",
       "Hope            25.0    30.0          30.0          25.0          30.0\n",
       "Nostalgia       22.0    35.0          28.0          15.0          20.0\n",
       "Relief          20.0    28.0          10.0          18.0          15.0\n",
       "Desperation      7.0     4.0           4.0           8.0           5.0\n",
       "Insecurity      13.0     6.0           5.0           5.0          10.0\n",
       "Pride           45.0    38.0          45.0          33.0          35.0\n",
       "Satisfaction    38.0    45.0          40.0          38.0          40.0\n",
       "Sympathy        15.0    10.0           5.0           5.0          10.0\n",
       "Disappointment  10.0    12.0           8.0          12.0           5.0\n",
       "Resentment       9.0     5.0           3.0           5.0           5.0\n",
       "Embarrassment    8.0     7.0           5.0           5.0           8.0\n",
       "Delight         40.0    37.0          35.0          30.0          38.0\n",
       "Courage         35.0    10.0          12.0          25.0          15.0\n",
       "Frustration     15.0     9.0           8.0          10.0          10.0\n",
       "Pessimism        6.0     3.0           5.0           5.0           5.0\n",
       "Desire          30.0    20.0          30.0          28.0          38.0\n",
       "Fascination     27.0    22.0          25.0          22.0          30.0\n",
       "Optimism        30.0    30.0          28.0          27.0          35.0\n",
       "Compassion      13.0    11.0          10.0           8.0          10.0\n",
       "Melancholy       8.0    12.0           8.0           8.0           8.0\n",
       "Shock           20.0     6.0          10.0          10.0          18.0\n",
       "Vindication     10.0     5.0           5.0          10.0           5.0\n",
       "Suspicion       15.0     4.0           5.0           7.0          10.0\n",
       "Serenity        18.0    20.0          20.0          20.0          25.0"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_brand_list = 'no'\n",
    "number = 3\n",
    "emotions_df, scores_df = check_data_exists(model, api_key, db_name, update_brand_list)\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from database...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nike</th>\n",
       "      <th>Levi's</th>\n",
       "      <th>Ralph Lauren</th>\n",
       "      <th>Under Armour</th>\n",
       "      <th>Calvin Klein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nike  Levi's  Ralph Lauren  Under Armour  Calvin Klein\n",
       "0  45.0    40.0          40.0          35.0          40.0\n",
       "1  10.0    10.0          10.0          10.0           5.0\n",
       "2  12.0     5.0           5.0           5.0          10.0\n",
       "3  15.0     8.0           8.0          15.0           8.0\n",
       "4  35.0    25.0          15.0          20.0          20.0"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_brand_list = 'no'\n",
    "number = 3\n",
    "emotions_df, scores_df = check_data_exists(model, api_key, db_name, update_brand_list)\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion_id   emotion\n",
       "0           0       Joy\n",
       "1           1   Sadness\n",
       "2           2     Anger\n",
       "3           3      Fear\n",
       "4           4  Surprise"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database: ['emotions', 'brands', 'association_scores']\n"
     ]
    }
   ],
   "source": [
    "with sqlite3.connect(os.path.abspath(db_name)) as conn:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    table_names = [table[0] for table in tables]\n",
    "    print(\"Tables in the database:\", table_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df(thing, model, emotions, api_key)\n",
    "df_cleaned = df.dropna(axis=1)\n",
    "\n",
    "dfs = get_dfs(things, model, emotions, api_key)\n",
    "dfs_cleaned = dfs.dropna(axis=1)\n",
    "\n",
    "\n",
    "result = get_similarity(df_cleaned, dfs_cleaned, number)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>info</th>\n",
       "      <th>scores_info</th>\n",
       "      <th>gpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Founded in 1964, Nike is a multinational corpo...</td>\n",
       "      <td>Nike, as a popular and successful brand, evoke...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Levi's</td>\n",
       "      <td>Founded in 1853, Levi's is renowned for its de...</td>\n",
       "      <td>Levi's is a well-established brand known for i...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   brand                                               info  \\\n",
       "0   0    Nike  Founded in 1964, Nike is a multinational corpo...   \n",
       "1   1  Levi's  Founded in 1853, Levi's is renowned for its de...   \n",
       "\n",
       "                                         scores_info                gpt  \n",
       "0  Nike, as a popular and successful brand, evoke...  gpt-4o-2024-08-06  \n",
       "1  Levi's is a well-established brand known for i...  gpt-4o-2024-08-06  "
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>info</th>\n",
       "      <th>scores_info</th>\n",
       "      <th>gpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Founded in 1964, Nike is a multinational corpo...</td>\n",
       "      <td>Nike, as a popular and successful brand, evoke...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Levi's</td>\n",
       "      <td>Founded in 1853, Levi's is renowned for its de...</td>\n",
       "      <td>Levi's is a well-established brand known for i...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ralph Lauren</td>\n",
       "      <td>Established in 1967, Ralph Lauren is a luxury ...</td>\n",
       "      <td>Ralph Lauren, as a renowned fashion brand, is ...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Under Armour</td>\n",
       "      <td>Founded in 1996, Under Armour is a leading bra...</td>\n",
       "      <td>Under Armour is a well-regarded athletic wear ...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Calvin Klein</td>\n",
       "      <td>Launched in 1968, Calvin Klein is an iconic fa...</td>\n",
       "      <td>Calvin Klein, being a renowned fashion brand, ...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         brand                                               info  \\\n",
       "0   0          Nike  Founded in 1964, Nike is a multinational corpo...   \n",
       "1   1        Levi's  Founded in 1853, Levi's is renowned for its de...   \n",
       "2   2  Ralph Lauren  Established in 1967, Ralph Lauren is a luxury ...   \n",
       "3   3  Under Armour  Founded in 1996, Under Armour is a leading bra...   \n",
       "4   4  Calvin Klein  Launched in 1968, Calvin Klein is an iconic fa...   \n",
       "\n",
       "                                         scores_info                gpt  \n",
       "0  Nike, as a popular and successful brand, evoke...  gpt-4o-2024-08-06  \n",
       "1  Levi's is a well-established brand known for i...  gpt-4o-2024-08-06  \n",
       "2  Ralph Lauren, as a renowned fashion brand, is ...  gpt-4o-2024-08-06  \n",
       "3  Under Armour is a well-regarded athletic wear ...  gpt-4o-2024-08-06  \n",
       "4  Calvin Klein, being a renowned fashion brand, ...  gpt-4o-2024-08-06  "
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with sqlite3.connect(os.path.abspath(db_name)) as conn:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name ='brands';\")\n",
    "    query = \"SELECT * FROM 'brands'\" \n",
    "    df = pd.read_sql_query(query, conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database: []\n"
     ]
    }
   ],
   "source": [
    "#check the databse tables, drop tables and check again: testing check_emotions_exists and check_brands_exists\n",
    "# with sqlite3.connect(os.path.abspath(db_name)) as conn:\n",
    "#     cursor = conn.cursor()\n",
    "#     cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "#     tables = cursor.fetchall()\n",
    "#     table_names = [table[0] for table in tables]\n",
    "#     print(\"Tables in the database:\", table_names)\n",
    "#     for table in table_names:\n",
    "#         query = f'SELECT * FROM {table}' \n",
    "#         table = pd.read_sql_query(query, conn)\n",
    "#         print(table.head())\n",
    "        \n",
    "# # Drop all tables and check again the above works\n",
    "# with sqlite3.connect(os.path.abspath(db_name)) as conn:\n",
    "#     cursor = conn.cursor()\n",
    "#     cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "#     tables = cursor.fetchall()\n",
    "#     table_names = [table[0] for table in tables]\n",
    "#     print(\"Tables in the database:\", table_names)\n",
    "#     for table in table_names:\n",
    "#         cursor.execute(f\"DROP TABLE IF EXISTS {table};\")\n",
    "#         print(f\"Table {table} dropped\")\n",
    "#     conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
