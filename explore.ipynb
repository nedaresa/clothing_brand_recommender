{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import sqlite3\n",
    "from itertools import islice\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "#!pip install openai -U\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
    "model = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get human emotions    \n",
    " \n",
    "# Define the Pydantic model for the API response\n",
    "class EmotionsResponse(BaseModel):\n",
    "    Characteristics: List[str] = Field(None, description=\"List of non-redundant human emotions.\")\n",
    "\n",
    "def get_emotions(model: str) -> List[str]:\n",
    "    \"\"\"Gets a list of 50 unique and non-redundant human emotions using the specified gpt model.\"\"\"\n",
    "    \n",
    "    # Define system and user prompts\n",
    "    system_prompt = \"Find 50 different, exclusive and unique human emotions. \"\\\n",
    "    \"For example, pick joy or happiness, pick Shame or Embarrassment, pick Envy or Jealousy, \"\\\n",
    "    \"pick Hate or disgust or hatered or Resentment. \"\\\n",
    "\n",
    "    user_prompt = \"Select 50 different and unique human emotions.\"\n",
    "\n",
    "    try:\n",
    "        #Call the API to get the completion\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model= model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Be a helpful assistant.\"},\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"system\", \"content\": \"make sure to include either joy or happiness, not both.\"},\n",
    "                {\"role\": \"system\", \"content\": \"make sure to include either Shame or Embarrassment, not both\"},\n",
    "                {\"role\": \"system\", \"content\": \"make sure to include either Envy or Jealousy, not both\"},\n",
    "                {\"role\": \"system\", \"content\": \"make sure to include either Hate or disgust or hatered or Resentment\"},\n",
    "                {\"role\": \"system\", \"content\": \"Check again to remove redundant emotions. I only want unique emotions.\"},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            response_format=EmotionsResponse\n",
    "        )\n",
    "\n",
    "        #output returns in the defined pydantic style\n",
    "        output = completion.choices[0].message.parsed\n",
    "        return output.json()\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle exceptions such as API errors, etc\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return json.dumps({})\n",
    "\n",
    "# Example usage\n",
    "emotions = get_emotions(model= model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get 100 best selling American clothing brands \n",
    "\n",
    "# Define the Pydantic model for the API response\n",
    "class BrandsResponse(BaseModel):\n",
    "    Brands: List[str] = Field(None, description=\"Brands as a list of strings.\")\n",
    "\n",
    "def get_brands(model: str) -> List[str]:\n",
    "    \"\"\"Get 100 best selling American clothing brands using the specified gpt model.\"\"\"\n",
    "\n",
    "    try:\n",
    "        #Call the API to get the completion\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model= model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Be a helpful assistant.\"},\n",
    "                {\"role\": \"system\", \"content\": \"Find 100 non-redundant best selling American clothing brands.\"},\n",
    "                {\"role\": \"system\", \"content\": \"DONT MAKE ANY MISTAKES, check if you did any.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Give me 100 best selling American clothing brands.\"}\n",
    "            ],\n",
    "            response_format=BrandsResponse\n",
    "        )\n",
    "\n",
    "        #output returns in the defined pydantic style\n",
    "        output = completion.choices[0].message.parsed\n",
    "        return output.json()\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle exceptions such as API errors, etc\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return json.dumps({})\n",
    "\n",
    "# Example usage\n",
    "brands = get_brands(model= model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_ls = list(json.loads(emotions).values())[0]\n",
    "brands_ls = list(json.loads(brands).values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding brand in emotions space: Get association scores between an input and list of emotions\n",
    "\n",
    "Characteristic = Enum('Characteristic', dict([(emotion, emotion) for emotion in emotions_ls]))\n",
    "\n",
    "class EmotionalAssociationScore(BaseModel):\n",
    "    emotion: Characteristic\n",
    "    score: float\n",
    "\n",
    "class EmotionalAssociationScores(BaseModel):\n",
    "    associations: List[EmotionalAssociationScore] = Field(description=\"A list of emotions and associated scores\")\n",
    "\n",
    "def emotional_association_scores(\n",
    "        thing, \n",
    "        model,\n",
    "        emotions\n",
    "    ):\n",
    "    \n",
    "    prompt = f\"Assign emotional association scores between {0} and {len(emotions)} for the provided thing. \"\\\n",
    "    \"Assign a score for each of the following emotions. Briefly, explain the reason behind the association score.\"\\\n",
    "    \"Ensure the scores reflect the association strength for the specified thing. \"\\\n",
    "    \"Thing: \"\\\n",
    "    f\"{thing}\"\n",
    "            \n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model = model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Be a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=EmotionalAssociationScores,\n",
    "    )\n",
    "    #output returns in the defined pydantic style\n",
    "    output = completion.choices[0].message.parsed\n",
    "    return thing, output.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not using this for the moment\n",
    "# #Embedding brands in emotions space: \n",
    "# # tried nested prompt but decided to go with one prompt and a list comprehension\n",
    "# emotions= emotions_ls\n",
    "# associations_brands = [emotional_association_scores(thing, model, emotions) for thing in brands_ls[:3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(thing, model, emotions):\n",
    "    gpt = emotional_association_scores(thing, model, emotions)\n",
    "    data = list(json.loads(gpt[1]).values())[0]\n",
    "    df = pd.DataFrame(data)\n",
    "    df.rename(columns = {'score': gpt[0]}, inplace=True)\n",
    "    df.set_index('emotion', inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_dfs(things_ls, model, emotions):\n",
    "    merged_df = pd.DataFrame()\n",
    "    for thing in things_ls:\n",
    "        new_df = get_df(thing, model, emotions)\n",
    "        if merged_df.empty:\n",
    "            merged_df = new_df\n",
    "        else:\n",
    "            merged_df = pd.merge(merged_df, new_df, left_index=True, right_index=True, how='outer')\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "things_ls = brands_ls\n",
    "dfs = get_dfs(things_ls, model, emotions)\n",
    "# Drop columns with NaN values\n",
    "dfs_cleaned = dfs.dropna(axis=1)\n",
    "\n",
    "dfs_cleaned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set pandas to display all rows and columns\n",
    "# pd.set_option('display.max_rows', None)  # Show all rows\n",
    "# pd.set_option('display.max_columns', None)  # Show all columns\n",
    "# pd.set_option('display.width', None)  # Adjust display width to prevent column cutting\n",
    "# pd.set_option('display.max_colwidth', None)  # Show full content in columns\n",
    "# dfs.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Confirmed no need to l2 norm vectors for sklearn's cosine similarity:\n",
    "# # Define your original vectors\n",
    "# A = np.array([[2, 3]])\n",
    "# B = np.array([[5, 4]])\n",
    "\n",
    "# # Calculate cosine similarity without normalization\n",
    "# cosine_sim_without_norm = cosine_similarity(A, B)\n",
    "\n",
    "# # L2 normalize the vectors\n",
    "# A_normalized = A / np.linalg.norm(A)\n",
    "# B_normalized = B / np.linalg.norm(B)\n",
    "\n",
    "# # Calculate cosine similarity with normalization\n",
    "# cosine_sim_with_norm = cosine_similarity(A_normalized, B_normalized)\n",
    "\n",
    "# # Print the outputs\n",
    "# print(\"Cosine Similarity without normalization:\")\n",
    "# print(cosine_sim_without_norm[0][0])  # Output from unnormalized vectors\n",
    "\n",
    "# print(\"\\nCosine Similarity with normalization:\")\n",
    "# print(cosine_sim_with_norm[0][0])      # Output from normalized vectors\n",
    "# cosine_sim_without_norm[0][0]==cosine_sim_with_norm[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_similarity(df, dfs):\n",
    "    similarities = dict()\n",
    "\n",
    "    # Reshape Series to 2D array (required by cosine_similarity)\n",
    "    s1 = df.values.reshape(1, -1)\n",
    "\n",
    "    for col in list(dfs.columns):\n",
    "        # Reshape\n",
    "        s2= dfs[col].values.reshape(1, -1)\n",
    "\n",
    "        cosine_sim = cosine_similarity(s1, s2)\n",
    "        similarities[col]= cosine_sim[0][0]\n",
    "\n",
    "    sorted_dict = dict(sorted(similarities.items(), key=lambda item: item[1], reverse = True))\n",
    "\n",
    "    # Get the top 3 (highest similarity)\n",
    "    top_3 = list(dict(islice(sorted_dict.items(), 3)).keys())\n",
    "\n",
    "    return top_3\n",
    "\n",
    "get_similarity(df, dfs_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The cosine similarity ranges from -1 to 1, where:\n",
    "#1 indicates identical vectors (i.e., vectors point in the same direction).\n",
    "#0 indicates orthogonality (i.e., vectors are at a 90-degree angle to each other, no similarity).\n",
    "#-1 indicates opposite directions (i.e., vectors point in exactly opposite directions).\n",
    "#represents similarity between feature vectors, quantifying similarity between two vectors based on their direction, \n",
    "# irrespective of their magnitude.\n",
    "\n",
    "#embeddings happen in a much smaller space of emotions as oppossed to ordinary, more common embeddings in a large space as more commonly done with openai api (read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a method\n",
    "#embedding dimension is emotions\n",
    "#talk about options\n",
    "#get the brands, go through 50 emotins at a time\n",
    "#cosine: normalize first: l2 norm = 1\n",
    "#give instructions on readme on where key goes \n",
    "#first have everything in pandas df, then think about database\n",
    "# one module or package w 1 .py \n",
    "#adaptors that take in pydantic datatypes and will make into sql\n",
    "#argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to check emotion redundancy by looking at example groups \n",
    "#[i for i in list(json.loads(emotions).values())[0] if i in ['Joy', 'Happiness', 'Shame', 'Embarrassment', 'Envy', 'Jealousy' , 'Hate', 'disgust', 'hatered', 'Resentment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test0\n",
    "\n",
    "#Retrieve emotions from datbase or through openAI API\n",
    "# if os.path.exists('emotions.json'):\n",
    "#     with open('emotions.json', 'r') as f:\n",
    "#         emotions_json = json.load(f)\n",
    "# else:\n",
    "#     emotions_json = get_emotions(model, api_key)\n",
    "\n",
    "#test sqlite\n",
    "# with sqlite3.connect(os.path.abspath('database.db')) as conn:\n",
    "#     # Write the DataFrame to the database\n",
    "#     df.to_sql('mytable', conn, if_exists='replace', index=False)\n",
    "#     #cursor = conn.cursor()\n",
    "#     #cursor.execute('SELECT SQLITE_VERSION()')\n",
    "#     #data = cursor.fetchone()\n",
    "#     #print('SQLite version:', data)\n",
    "\n",
    "# query = \"SELECT * FROM mytable\"\n",
    "# with sqlite3.connect(os.path.abspath('database.db')) as conn:\n",
    "#     df_test= pd.read_sql_query(query, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test0\n",
    "#test\n",
    "\n",
    "class EmotionsResponse(BaseModel):\n",
    "    #None as default if value not provided\n",
    "    Emotions: List[str] = Field(None, description=\"List of non-redundant human emotions.\") \n",
    "\n",
    "def get_emotions(model: str, api_key: str) -> List[str]:\n",
    "    \"\"\"Gets a list of 50 unique and non-redundant human emotions using the specified gpt model.\"\"\"\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    system_prompt = \"Find 50 different, exclusive and unique human emotions. \"\\\n",
    "    \"For example, pick joy or happiness, pick Shame or Embarrassment, pick Envy or Jealousy, \"\\\n",
    "    \"pick Hate or disgust or hatered or Resentment. \"\\\n",
    "\n",
    "    user_prompt = \"Select 50 different and unique human emotions.\"\n",
    "\n",
    "    try:\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model= model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            response_format=EmotionsResponse\n",
    "        )\n",
    "\n",
    "        #output in the defined pydantic style\n",
    "        output = completion.choices[0].message.parsed\n",
    "        return output.json()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return json.dumps({})\n",
    "\n",
    "def get_emotions_df(model, api_key):\n",
    "    emotions_json = get_emotions(model, api_key)\n",
    "    emotions = list(json.loads(emotions_json).values())[0]\n",
    "    emotions_df = pd.DataFrame(emotions, columns = ['emotion'])\n",
    "    emotions_df['emotion_id'] = emotions_df.index\n",
    "    emotions_df = emotions_df[['emotion_id','emotion']]\n",
    "    return emotions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test1\n",
    "#Get 100 best selling American clothing brands using the Pydantic model for the API response\n",
    "class BrandResponse(BaseModel):\n",
    "    brand: str = Field(description=\"name as a string.\")\n",
    "    information: str = Field(description=\"Brand information as a string.\")\n",
    "class BrandsResponse(BaseModel):\n",
    "    brands: List[BrandResponse] = Field(description=\"A list of names and information.\")\n",
    "\n",
    "def get_brands(model: str, api_key: str) -> List[str]:\n",
    "    \"\"\"Get 5 best selling American clothing brands using the specified gpt model. Provide a brief information about each brand.\"\"\"\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    try:\n",
    "        #Call the API to get the completion\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model= model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Find 5 non-redundant best selling American clothing brands.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Give me 5 best selling American clothing brands and a brief information about each brand.\"}\n",
    "            ],\n",
    "            response_format=BrandsResponse\n",
    "        )\n",
    "        #output in the defined pydantic style\n",
    "        output = completion.choices[0].message.parsed\n",
    "\n",
    "        return output.json()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return json.dumps({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test2\n",
    "# Embedding and getting association scores between an input and list of emotions\n",
    "def emotional_association_scores(\n",
    "        thing, \n",
    "        model,\n",
    "        emotions, api_key\n",
    "    ):\n",
    "\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    Characteristic = Enum('Characteristic', dict([(emotion, emotion) for emotion in emotions]))\n",
    "\n",
    "    class EmotionalAssociationScore(BaseModel):\n",
    "        emotion: Characteristic\n",
    "        score: float\n",
    "\n",
    "    class EmotionalAssociationScores(BaseModel):\n",
    "        associations: List[EmotionalAssociationScore] = Field(description=\"A list of emotions and associated scores\")\n",
    "        explanation: str = Field(description=\"Briefly explaining the reason behind the association scores.\")\n",
    "\n",
    "    prompt = f\"Assign emotional association scores between {0} and {len(emotions)} for the provided thing. \"\\\n",
    "    \"Assign a score for each of the following emotions. Briefly, explain the reason behind the association score.\"\\\n",
    "    \"Ensure the scores reflect the association strength for the specified thing. \"\\\n",
    "    \"Thing: \"\\\n",
    "    f\"{thing}\"\n",
    "            \n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model = model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Be a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=EmotionalAssociationScores,\n",
    "    )\n",
    "    #output in the defined pydantic style\n",
    "    output = completion.choices[0].message.parsed\n",
    "    return thing, output.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test get_df\n",
    "def get_df(thing, model, emotions, api_key):\n",
    "    gpt = emotional_association_scores(thing, model, emotions, api_key)\n",
    "    data = list(json.loads(gpt[1]).values())[0]\n",
    "    df = pd.DataFrame(data)\n",
    "    df.rename(columns = {'score': gpt[0]}, inplace=True)\n",
    "    #df[f'explanation_for_{gpt[0]}'] = json.loads(gpt[1])['explanation']\n",
    "    df.set_index('emotion', inplace=True)\n",
    "    brand_name = gpt[0]\n",
    "    score_info = json.loads(gpt[1])['explanation']\n",
    "    return {brand_name: score_info}, df\n",
    "brand_scores = get_df(thing, model, emotions, api_key)\n",
    "\n",
    "\n",
    "def get_dfs(things, model, emotions, api_key):\n",
    "    things_scoreinfo = []\n",
    "    merged_df = pd.DataFrame()\n",
    "    for thing in things:\n",
    "        thing_scoreinfo = get_df(thing, model, emotions, api_key)[0]\n",
    "        things_scoreinfo.append(thing_scoreinfo)\n",
    "        new_df = get_df(thing, model, emotions, api_key)[1]\n",
    "        if merged_df.empty:\n",
    "            merged_df = new_df\n",
    "        else:\n",
    "            merged_df = pd.merge(merged_df, new_df, left_index=True, right_index=True, how='outer')\n",
    "    return things_scoreinfo, merged_df\n",
    "\n",
    "#merged_df.reset_index(inplace= True)\n",
    "\n",
    "\n",
    "def get_final_brands(model, api_key, emotions):\n",
    "    brands_df = pd.DataFrame(list(json.loads(get_brands(model, api_key)).values())[0])\n",
    "    brands_df.reset_index(inplace= True)\n",
    "    brands_df.rename({'information':'brand_info', 'index':'brand_id'}, axis = 1, inplace = True)\n",
    "    brands_df['gpt_version'] = model\n",
    "\n",
    "    brands_scores = get_dfs(brands_df['brand'], model, emotions, api_key)\n",
    "    brands_scoreinfo= brands_scores[0]\n",
    "    scoreinfo_df = pd.DataFrame([(k,v) for data in brands_scoreinfo for k,v in data.items()], columns = ['brand', 'scores_info'])\n",
    "    brands_df = pd.merge(brands_df, scoreinfo_df, how = 'left', on ='brand' )\n",
    "    brands_df = brands_df[['brand_id','brand','brand_info', 'scores_info','gpt_version']]\n",
    "    return brands_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotions doesn't exist so generating one.\n",
      "brands doesn't exist so generating one...\n"
     ]
    }
   ],
   "source": [
    "def check_emotions_exists(model, api_key, db_name, mytable):\n",
    "    with sqlite3.connect(os.path.abspath(db_name)) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name=?\", (mytable,))\n",
    "        if cursor.fetchone() is not None:\n",
    "            print(f'Reading {mytable} from database...')\n",
    "            query = f'SELECT * FROM {mytable}' \n",
    "            df = pd.read_sql_query(query, conn)\n",
    "        else:\n",
    "            print(f\"{mytable} doesn't exist so generating one...\")\n",
    "            df = get_emotions_df(model, api_key)\n",
    "            df.to_sql(f'{mytable}', conn, index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "def check_brands_exists(model, api_key, db_name, mytable, emotions, update_brand_list):\n",
    "    with sqlite3.connect(os.path.abspath(db_name)) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name=?\", (mytable,))\n",
    "        if cursor.fetchone() is None:\n",
    "            print(f\"{mytable} doesn't exist so generating one...\")\n",
    "            df = get_final_brands(model, api_key, emotions)\n",
    "            df.to_sql(f'{mytable}', conn, index=False)\n",
    "        else:\n",
    "            if update_brand_list == 'no':\n",
    "                print(f'Reading {mytable} from database...')\n",
    "                query = f'SELECT * FROM {mytable}' \n",
    "                df = pd.read_sql_query(query, conn)\n",
    "            else:\n",
    "                print(f\"Generating {mytable}...\")\n",
    "                df = get_final_brands(model, api_key, emotions)\n",
    "                df.to_sql(f'{mytable}', conn, if_exists = 'replace', index=False)            \n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "model = \"gpt-4o-2024-08-06\"\n",
    "api_key=os.environ.get('OPENAI_API_KEY')\n",
    "db_name = 'database.db'\n",
    "update_brand_list = 'no'\n",
    "number = 3\n",
    "emotions_df = check_emotions_exists(model, api_key, db_name, 'emotions')\n",
    "emotions = emotions_df['emotion']\n",
    "brands_df = check_brands_exists(model, api_key, db_name, 'brands', emotions, update_brand_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database: []\n"
     ]
    }
   ],
   "source": [
    "#check the databse tables, drop tables and check again: testing check_emotions_exists and check_brands_exists\n",
    "# with sqlite3.connect(os.path.abspath(db_name)) as conn:\n",
    "#     cursor = conn.cursor()\n",
    "#     cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "#     tables = cursor.fetchall()\n",
    "#     table_names = [table[0] for table in tables]\n",
    "#     print(\"Tables in the database:\", table_names)\n",
    "#     for table in table_names:\n",
    "#         query = f'SELECT * FROM {table}' \n",
    "#         table = pd.read_sql_query(query, conn)\n",
    "#         print(table.head())\n",
    "        \n",
    "# # Drop all tables and check again the above works\n",
    "# with sqlite3.connect(os.path.abspath(db_name)) as conn:\n",
    "#     cursor = conn.cursor()\n",
    "#     cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "#     tables = cursor.fetchall()\n",
    "#     table_names = [table[0] for table in tables]\n",
    "#     print(\"Tables in the database:\", table_names)\n",
    "#     for table in table_names:\n",
    "#         cursor.execute(f\"DROP TABLE IF EXISTS {table};\")\n",
    "#         print(f\"Table {table} dropped\")\n",
    "#     conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_similarity(df, dfs, number):\n",
    "    dfs.set_index('emotion', inplace=True)\n",
    "\n",
    "    similarities = dict()\n",
    "    df_cosine = df[[col for col in df.columns if 'explanation' not in col]]\n",
    "    # Reshape Series to 2D array (required by cosine_similarity)\n",
    "    s1 = df_cosine.values.reshape(1, -1)\n",
    "\n",
    "    for col in list(dfs.columns):\n",
    "        dfs_cosine = dfs[[col for col in dfs.columns if 'explanation' not in col and 'gpt' not in col]]\n",
    "        s2= dfs_cosine[col].values.reshape(1, -1)\n",
    "        cosine_sim = cosine_similarity(s1, s2)\n",
    "        similarities[col]= cosine_sim[0][0]\n",
    "\n",
    "    sorted_dict = dict(sorted(similarities.items(), key=lambda item: item[1], reverse = True))\n",
    "\n",
    "    # Get the top number of recommendations based on similarity\n",
    "    recommendations = list(dict(islice(sorted_dict.items(), number)).keys())\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df(thing, model, emotions, api_key)\n",
    "df_cleaned = df.dropna(axis=1)\n",
    "\n",
    "dfs = get_dfs(things, model, emotions, api_key)\n",
    "dfs_cleaned = dfs.dropna(axis=1)\n",
    "\n",
    "\n",
    "result = get_similarity(df_cleaned, dfs_cleaned, number)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Contentment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Excitement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Yearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Nostalgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Awe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Relief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Gratitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Hatred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Resentment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Guilt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Embarrassment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Jealousy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Envy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Pride</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Humility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Compassion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Empathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Confusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Boredom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>Frustration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Curiosity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>Admiration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>Suspicion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>Courage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>Panic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>Desperation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>Serenity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>Melancholy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>Ecstasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>Indignation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>Neglect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>Solitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>Vulnerability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>Uncertainty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>Hostility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>Disappointment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>Loneliness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>Thrill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    emotion_id         emotion\n",
       "0            0             Joy\n",
       "1            1          Sorrow\n",
       "2            2            Fear\n",
       "3            3         Disgust\n",
       "4            4        Surprise\n",
       "5            5           Trust\n",
       "6            6    Anticipation\n",
       "7            7           Anger\n",
       "8            8     Contentment\n",
       "9            9      Excitement\n",
       "10          10        Yearning\n",
       "11          11       Nostalgia\n",
       "12          12             Awe\n",
       "13          13            Hope\n",
       "14          14          Relief\n",
       "15          15       Gratitude\n",
       "16          16            Love\n",
       "17          17          Hatred\n",
       "18          18      Resentment\n",
       "19          19           Guilt\n",
       "20          20           Shame\n",
       "21          21   Embarrassment\n",
       "22          22        Jealousy\n",
       "23          23            Envy\n",
       "24          24           Pride\n",
       "25          25        Humility\n",
       "26          26      Compassion\n",
       "27          27         Empathy\n",
       "28          28       Confusion\n",
       "29          29         Boredom\n",
       "30          30     Frustration\n",
       "31          31       Curiosity\n",
       "32          32      Admiration\n",
       "33          33       Suspicion\n",
       "34          34         Courage\n",
       "35          35           Panic\n",
       "36          36     Desperation\n",
       "37          37        Serenity\n",
       "38          38      Melancholy\n",
       "39          39         Ecstasy\n",
       "40          40     Indignation\n",
       "41          41         Neglect\n",
       "42          42        Solitude\n",
       "43          43   Vulnerability\n",
       "44          44     Uncertainty\n",
       "45          45       Hostility\n",
       "46          46  Disappointment\n",
       "47          47      Loneliness\n",
       "48          48          Thrill"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>brand_info</th>\n",
       "      <th>scores_info</th>\n",
       "      <th>gpt_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Founded in 1964 and headquartered in Beaverton...</td>\n",
       "      <td>Nike is often associated with joy, pride, and ...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ralph Lauren</td>\n",
       "      <td>Established in 1967, Ralph Lauren is synonymou...</td>\n",
       "      <td>Ralph Lauren is primarily associated with luxu...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Levi's</td>\n",
       "      <td>Founded in 1853 in San Francisco, California, ...</td>\n",
       "      <td>Levi’s, as a brand, evokes varying emotional a...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Started in 1985, Tommy Hilfiger is known for i...</td>\n",
       "      <td>Tommy Hilfiger, as a global brand, is often as...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Under Armour</td>\n",
       "      <td>Founded in 1996 and based in Baltimore, Maryla...</td>\n",
       "      <td>Under Armour is a popular athletic brand, and ...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand_id           brand  \\\n",
       "0         0            Nike   \n",
       "1         1    Ralph Lauren   \n",
       "2         2          Levi's   \n",
       "3         3  Tommy Hilfiger   \n",
       "4         4    Under Armour   \n",
       "\n",
       "                                          brand_info  \\\n",
       "0  Founded in 1964 and headquartered in Beaverton...   \n",
       "1  Established in 1967, Ralph Lauren is synonymou...   \n",
       "2  Founded in 1853 in San Francisco, California, ...   \n",
       "3  Started in 1985, Tommy Hilfiger is known for i...   \n",
       "4  Founded in 1996 and based in Baltimore, Maryla...   \n",
       "\n",
       "                                         scores_info        gpt_version  \n",
       "0  Nike is often associated with joy, pride, and ...  gpt-4o-2024-08-06  \n",
       "1  Ralph Lauren is primarily associated with luxu...  gpt-4o-2024-08-06  \n",
       "2  Levi’s, as a brand, evokes varying emotional a...  gpt-4o-2024-08-06  \n",
       "3  Tommy Hilfiger, as a global brand, is often as...  gpt-4o-2024-08-06  \n",
       "4  Under Armour is a popular athletic brand, and ...  gpt-4o-2024-08-06  "
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
