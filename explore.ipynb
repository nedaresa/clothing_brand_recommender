{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import sqlite3\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "#!pip install openai -U\n",
    "from openai import OpenAI\n",
    "key=os.environ.get('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=key)\n",
    "model = \"gpt-4o-2024-08-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding brand in emotions space: Get association scores between an input and list of emotions\n",
    "\n",
    "Characteristic = Enum('Characteristic', dict([(emotion, emotion) for emotion in emotions_ls]))\n",
    "\n",
    "class EmotionalAssociationScore(BaseModel):\n",
    "    emotion: Characteristic\n",
    "    score: float\n",
    "\n",
    "class EmotionalAssociationScores(BaseModel):\n",
    "    associations: List[EmotionalAssociationScore] = Field(description=\"A list of emotions and associated scores\")\n",
    "\n",
    "def emotional_association_scores(\n",
    "        thing, \n",
    "        model,\n",
    "        emotions\n",
    "    ):\n",
    "    \n",
    "    prompt = f\"Assign emotional association scores between {0} and {len(emotions)} for the provided thing. \"\\\n",
    "    \"Assign a score for each of the following emotions. Briefly, explain the reason behind the association score.\"\\\n",
    "    \"Ensure the scores reflect the association strength for the specified thing. \"\\\n",
    "    \"Thing: \"\\\n",
    "    f\"{thing}\"\n",
    "            \n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model = model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Be a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=EmotionalAssociationScores,\n",
    "    )\n",
    "    #output returns in the defined pydantic style\n",
    "    output = completion.choices[0].message.parsed\n",
    "    return thing, output.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not using this for the moment\n",
    "# #Embedding brands in emotions space: \n",
    "# # tried nested prompt but decided to go with one prompt and a list comprehension\n",
    "# emotions= emotions_ls\n",
    "# associations_brands = [emotional_association_scores(thing, model, emotions) for thing in brands_ls[:3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(thing, model, emotions):\n",
    "    gpt = emotional_association_scores(thing, model, emotions)\n",
    "    data = list(json.loads(gpt[1]).values())[0]\n",
    "    df = pd.DataFrame(data)\n",
    "    df.rename(columns = {'score': gpt[0]}, inplace=True)\n",
    "    df.set_index('emotion', inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_dfs(things_ls, model, emotions):\n",
    "    merged_df = pd.DataFrame()\n",
    "    for thing in things_ls:\n",
    "        new_df = get_df(thing, model, emotions)\n",
    "        if merged_df.empty:\n",
    "            merged_df = new_df\n",
    "        else:\n",
    "            merged_df = pd.merge(merged_df, new_df, left_index=True, right_index=True, how='outer')\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "things_ls = brands_ls\n",
    "dfs = get_dfs(things_ls, model, emotions)\n",
    "# Drop columns with NaN values\n",
    "dfs_cleaned = dfs.dropna(axis=1)\n",
    "\n",
    "dfs_cleaned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas to display all rows and columns\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)  # Adjust display width to prevent column cutting\n",
    "pd.set_option('display.max_colwidth', None)  # Show full content in columns\n",
    "# dfs.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Confirmed no need to l2 norm vectors for sklearn's cosine similarity:\n",
    "# # Define your original vectors\n",
    "# A = np.array([[2, 3]])\n",
    "# B = np.array([[5, 4]])\n",
    "\n",
    "# # Calculate cosine similarity without normalization\n",
    "# cosine_sim_without_norm = cosine_similarity(A, B)\n",
    "\n",
    "# # L2 normalize the vectors\n",
    "# A_normalized = A / np.linalg.norm(A)\n",
    "# B_normalized = B / np.linalg.norm(B)\n",
    "\n",
    "# # Calculate cosine similarity with normalization\n",
    "# cosine_sim_with_norm = cosine_similarity(A_normalized, B_normalized)\n",
    "\n",
    "# # Print the outputs\n",
    "# print(\"Cosine Similarity without normalization:\")\n",
    "# print(cosine_sim_without_norm[0][0])  # Output from unnormalized vectors\n",
    "\n",
    "# print(\"\\nCosine Similarity with normalization:\")\n",
    "# print(cosine_sim_with_norm[0][0])      # Output from normalized vectors\n",
    "# cosine_sim_without_norm[0][0]==cosine_sim_with_norm[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_similarity(df, dfs):\n",
    "    similarities = dict()\n",
    "\n",
    "    # Reshape Series to 2D array (required by cosine_similarity)\n",
    "    s1 = df.values.reshape(1, -1)\n",
    "\n",
    "    for col in list(dfs.columns):\n",
    "        # Reshape\n",
    "        s2= dfs[col].values.reshape(1, -1)\n",
    "\n",
    "        cosine_sim = cosine_similarity(s1, s2)\n",
    "        similarities[col]= cosine_sim[0][0]\n",
    "\n",
    "    sorted_dict = dict(sorted(similarities.items(), key=lambda item: item[1], reverse = True))\n",
    "\n",
    "    # Get the top 3 (highest similarity)\n",
    "    top_3 = list(dict(islice(sorted_dict.items(), 3)).keys())\n",
    "\n",
    "    return top_3\n",
    "\n",
    "get_similarity(df, dfs_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The cosine similarity ranges from -1 to 1, where:\n",
    "#1 indicates identical vectors (i.e., vectors point in the same direction).\n",
    "#0 indicates orthogonality (i.e., vectors are at a 90-degree angle to each other, no similarity).\n",
    "#-1 indicates opposite directions (i.e., vectors point in exactly opposite directions).\n",
    "#represents similarity between feature vectors, quantifying similarity between two vectors based on their direction, \n",
    "# irrespective of their magnitude.\n",
    "\n",
    "#embeddings happen in a much smaller space of emotions as oppossed to ordinary, more common embeddings in a large space as more commonly done with openai api (read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a method\n",
    "#embedding dimension is emotions\n",
    "#talk about options\n",
    "#get the brands, go through 50 emotins at a time\n",
    "#cosine: normalize first: l2 norm = 1\n",
    "#give instructions on readme on where key goes \n",
    "#first have everything in pandas df, then think about database\n",
    "# one module or package w 1 .py \n",
    "#adaptors that take in pydantic datatypes and will make into sql\n",
    "#argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #to check emotion redundancy by looking at example groups \n",
    "#[i for i in list(json.loads(emotions).values())[0] if i in ['Joy', 'Happiness', 'Shame', 'Embarrassment', 'Envy', 'Jealousy' , 'Hate', 'disgust', 'hatered', 'Resentment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test0\n",
    "\n",
    "#Retrieve emotions from datbase or through openAI API\n",
    "# if os.path.exists('emotions.json'):\n",
    "#     with open('emotions.json', 'r') as f:\n",
    "#         emotions_json = json.load(f)\n",
    "# else:\n",
    "#     emotions_json = get_emotions(model, api_key)\n",
    "\n",
    "#test sqlite\n",
    "# with sqlite3.connect(os.path.abspath('database.db')) as conn:\n",
    "#     # Write the DataFrame to the database\n",
    "#     df.to_sql('mytable', conn, if_exists='replace', index=False)\n",
    "#     #cursor = conn.cursor()\n",
    "#     #cursor.execute('SELECT SQLITE_VERSION()')\n",
    "#     #data = cursor.fetchone()\n",
    "#     #print('SQLite version:', data)\n",
    "\n",
    "# query = \"SELECT * FROM mytable\"\n",
    "# with sqlite3.connect(os.path.abspath('database.db')) as conn:\n",
    "#     df_test= pd.read_sql_query(query, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "# Get human emotions using the Pydantic model for the API response\n",
    "\n",
    "class EmotionsResponse(BaseModel):\n",
    "    #None as default if value not provided\n",
    "    Emotions: List[str] = Field(None, description=\"List of non-redundant human emotions.\") \n",
    "\n",
    "def get_emotions(model: str, key: str) -> List[str]:\n",
    "    \"\"\"Gets a list of 50 unique and non-redundant human emotions using the specified gpt model.\"\"\"\n",
    "    client = OpenAI(api_key=key)\n",
    "\n",
    "    system_prompt = \"Find 50 different, exclusive and unique human emotions. \"\\\n",
    "    \"For example, pick joy or happiness, pick Shame or Embarrassment, pick Envy or Jealousy, \"\\\n",
    "    \"pick Hate or disgust or hatered or Resentment. \"\\\n",
    "\n",
    "    user_prompt = \"Select 50 different and unique human emotions.\"\n",
    "\n",
    "    try:\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model= model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            response_format=EmotionsResponse\n",
    "        )\n",
    "\n",
    "        #output in the defined pydantic style\n",
    "        output = completion.choices[0].message.parsed\n",
    "        return output.json()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while trying to get emotions: {e}\")\n",
    "        return json.dumps({})\n",
    "\n",
    "\n",
    "#Get 100 best selling American clothing brands\n",
    "class BrandResponse(BaseModel):\n",
    "    name: str = Field(description=\"Brand name as a string.\")\n",
    "    brand_info: str = Field(description=\"Brand information as a string.\")\n",
    "class BrandsResponse(BaseModel):\n",
    "    brands: List[BrandResponse] = Field(description=\"A list of brand names and information.\")\n",
    "\n",
    "def get_brands(model: str, key: str) -> List[str]:\n",
    "    \"\"\"Get 5 best selling American clothing brands using the specified gpt model. Provide a brief information about each brand.\"\"\"\n",
    "    client = OpenAI(api_key=key)\n",
    "    try:\n",
    "        #Call the API to get the completion\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model= model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Find 5 non-redundant best selling American clothing brands.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Give me 5 best selling American clothing brands and a brief information about each brand.\"}\n",
    "            ],\n",
    "            response_format=BrandsResponse\n",
    "        )\n",
    "        #output in the defined pydantic style\n",
    "        output = completion.choices[0].message.parsed\n",
    "\n",
    "        return output.json()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while trying to get brands: {e}\")\n",
    "        return json.dumps({})\n",
    "\n",
    "\n",
    "# Embedding and getting association scores between an input and emotions\n",
    "\n",
    "def get_scores(thing, emotions, model, key):\n",
    "\n",
    "    Characteristic = Enum('Characteristic', dict([(emotion, emotion) for emotion in emotions]))\n",
    "\n",
    "    class EmotionalAssociationScore(BaseModel):\n",
    "        emotion: Characteristic\n",
    "        score: float\n",
    "\n",
    "    class EmotionalAssociationScores(BaseModel):\n",
    "        associations: List[EmotionalAssociationScore] = Field(description=\"List of dictionaries with 'emotion' and 'score' as keys for each dictionary\")\n",
    "        explanation: str = Field(description=\"String explaining the association scores.\")\n",
    "    \n",
    "    client = OpenAI(api_key=key)\n",
    "\n",
    "    prompt = f\"Assign emotional association scores, with each score reflecting the association strength between \"\\\n",
    "    f\"{thing} and each of the given {emotions}. Each score should be between 0 \"\\\n",
    "    f\"and {len(emotions)}. Briefly explain the reason behind the association scores.\"\\\n",
    "            \n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model = model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Be a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format=EmotionalAssociationScores,\n",
    "    )\n",
    "    #output in the defined pydantic style\n",
    "    output = completion.choices[0].message.parsed\n",
    "    return output.json()\n",
    "\n",
    "def get_emotions_df(model, key):\n",
    "    gpt = get_emotions(model, key)\n",
    "    ls = list(json.loads(gpt).values())[0]\n",
    "    df = pd.DataFrame(ls, columns = ['emotion'])\n",
    "    df['emotion_id'] = df.index\n",
    "    df = df[['emotion_id','emotion']]\n",
    "    return df\n",
    "\n",
    "def get_scores_thing(thing, emotions_df, model, key):\n",
    "    emotions = list(emotions_df['emotion'].values)\n",
    "    gpt = get_scores(thing, emotions, model, key)\n",
    "    scoresinfo = json.loads(gpt)['explanation']\n",
    "\n",
    "    df = pd.DataFrame(json.loads(gpt)['associations'])\n",
    "    df.rename(columns = {'score': thing}, inplace=True)\n",
    "    #merge to get emotion ids\n",
    "    df = pd.merge(df, emotions_df, on ='emotion', how ='inner')\n",
    "    df.drop('emotion', axis = 1, inplace=True)\n",
    "    df= df[['emotion_id',f'{thing}']]\n",
    "    return ({thing: scoresinfo}, df)\n",
    "\n",
    "def get_scores_things(things, emotions_df, model, key):\n",
    "    scoreinfos = []\n",
    "    merged_df = pd.DataFrame()\n",
    "    for thing in things:\n",
    "        scoreinfo, new_df = get_scores_thing(thing, emotions_df, model, key)\n",
    "        scoreinfos.append(scoreinfo)\n",
    "        if merged_df.empty:\n",
    "            merged_df = new_df\n",
    "        else:\n",
    "            merged_df = pd.merge(merged_df, new_df, on='emotion_id', how='inner')\n",
    "    return (scoreinfos, merged_df)\n",
    "\n",
    "def get_brands_scores(emotions_df, model, key):\n",
    "    gpt = get_brands(model, key)\n",
    "\n",
    "    brands_df = pd.DataFrame(list(json.loads(gpt).values())[0])\n",
    "    brands_df.reset_index(inplace= True)\n",
    "    brands_df.rename({'index':'brand_id'}, axis = 1, inplace = True)\n",
    "    scoreinfos, scores_brands= get_scores_things(brands_df['name'], emotions_df, model, key)\n",
    "    scoreinfos_df= pd.DataFrame([(k,v) for data in scoreinfos for k,v in data.items()], columns = ['name', 'scores_info'])\n",
    "    brands_df = pd.merge(brands_df, scoreinfos_df, how = 'left', on ='name' )\n",
    "    brands_df['gpt'] = model\n",
    "    brands_df = brands_df[['brand_id','name','brand_info', 'scores_info','gpt']]\n",
    "\n",
    "    scores_brands = pd.melt(scores_brands, id_vars='emotion_id', value_vars =list(scores_brands.columns))\n",
    "    scores_brands.rename(columns = {'variable':'name','value':'score'}, inplace=True)\n",
    "    scores_brands = pd.merge(scores_brands, brands_df[['brand_id','name']], on ='name', how ='inner')\n",
    "    scores_brands.drop('name', axis= 1, inplace=True)\n",
    "    scores_brands = scores_brands[['emotion_id','brand_id','score']]\n",
    "    \n",
    "    return (brands_df, scores_brands)\n",
    "\n",
    "def get_similarity(brands_df, scores_thing, scores_brands, number):\n",
    "    similarities = dict()\n",
    "\n",
    "    scores_thing.sort_values(by='emotion_id',inplace=True)\n",
    "    scores_thing.set_index('emotion_id', inplace=True)\n",
    "    # Reshape Series to 2D array (required by cosine_similarity)\n",
    "    s1 = scores_thing.values.reshape(1, -1)\n",
    "\n",
    "    brand_ids = list(scores_brands['brand_id'].unique())\n",
    "    for brand_id in brand_ids:\n",
    "        df_brand = scores_brands.loc[scores_brands['brand_id']==brand_id]\n",
    "        df_brand = df_brand.sort_values(by='emotion_id')\n",
    "        df_brand= df_brand.set_index('emotion_id')\n",
    "        s2= df_brand['score'].values.reshape(1, -1)\n",
    "        cosine_sim = cosine_similarity(s1, s2)\n",
    "        similarities[brand_id]= cosine_sim[0][0]\n",
    "    #replace brand id with name \n",
    "    name_id = dict(zip(brands_df['name'], brands_df['brand_id']))\n",
    "    similarities = {k: similarities[v] for k, v in name_id.items() if v in similarities}\n",
    "    sorted_s = sorted(similarities.items(), key=lambda item: item[1], reverse = True)\n",
    "    recommendations = list(dict(sorted_s[:number]).keys())\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Fear of God'\n",
    "with sqlite3.connect(os.path.abspath('database.db')) as conn:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name ='brands';\")\n",
    "    query = \"SELECT * FROM 'brands'\" \n",
    "    df = pd.read_sql_query(query, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98    Founded in 2013 by Jerry Lorenzo, known for luxury streetwear and casual essentials.\n",
       "Name: brand_info, dtype: object"
      ]
     },
     "execution_count": 937,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['name']=='Fear of God']['brand_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database: [('emotions',), ('brands',), ('association_scores',)]\n",
      "   emotion_id emotion\n",
      "0           0     Joy\n",
      "1           1   Shame\n",
      "2           2    Envy\n",
      "3           3    Hate\n",
      "4           4   Pride\n",
      "(49, 2)\n",
      "   brand_id            name  \\\n",
      "0         0            Nike   \n",
      "1         1    Ralph Lauren   \n",
      "2         2          Levi's   \n",
      "3         3    Calvin Klein   \n",
      "4         4  Tommy Hilfiger   \n",
      "\n",
      "                                          brand_info  \\\n",
      "0  Established in 1964, Nike is a leading sportsw...   \n",
      "1  Founded in 1967, Ralph Lauren offers a range o...   \n",
      "2  Originating in 1853, Levi's is famous for its ...   \n",
      "3  Launched in 1968, Calvin Klein is renowned for...   \n",
      "4  Since 1985, Tommy Hilfiger has been a key play...   \n",
      "\n",
      "                                         scores_info                gpt  \n",
      "0  Nike, as a leading global sports brand, is str...  gpt-4o-2024-08-06  \n",
      "1  The brand Ralph Lauren is often associated wit...  gpt-4o-2024-08-06  \n",
      "2  Levi's is a well-known and trusted denim brand...  gpt-4o-2024-08-06  \n",
      "3  Calvin Klein is strongly associated with emoti...  gpt-4o-2024-08-06  \n",
      "4  Tommy Hilfiger is generally associated with po...  gpt-4o-2024-08-06  \n",
      "(100, 5)\n",
      "   emotion_id  brand_id  score\n",
      "0           0         0   40.0\n",
      "1           1         0    5.0\n",
      "2           2         0   30.0\n",
      "3           3         0   10.0\n",
      "4           4         0   35.0\n",
      "(4508, 3)\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "#check the databse tables, drop tables and check again: testing check_emotions_exists and check_brands_exists\n",
    "with sqlite3.connect(os.path.abspath('database.db')) as conn:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    print(\"Tables in the database:\", tables)\n",
    "    for table in tables:\n",
    "        query = f'SELECT * FROM {table[0]}' \n",
    "        table = pd.read_sql_query(query, conn)\n",
    "        print(table.head())\n",
    "        print(table.shape)\n",
    "        \n",
    "# # Drop all tables and check again the above works\n",
    "# with sqlite3.connect(os.path.abspath('database.db')) as conn:\n",
    "#     cursor = conn.cursor()\n",
    "#     cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "#     tables = cursor.fetchall()\n",
    "#     print(\"Tables in the database:\", tables)\n",
    "#     for table in tables:\n",
    "#         cursor.execute(f\"DROP TABLE IF EXISTS {table[0]};\")\n",
    "#         print(f\"Table {table[0]} dropped\")\n",
    "#     conn.commit()\n",
    "\n",
    "#drop one table\n",
    "# with sqlite3.connect(os.path.abspath('database.db')) as conn:\n",
    "#     cursor = conn.cursor()\n",
    "#     cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name in ('emotions');\")\n",
    "#     tables = cursor.fetchall()\n",
    "#     for table in tables:\n",
    "#         cursor.execute(f\"DROP TABLE IF EXISTS {table[0]};\")\n",
    "#         print(f\"Table {table[0]} dropped\")\n",
    "#     conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "# def check_emotions_exists(mytable, model, key):\n",
    "#     with sqlite3.connect(os.path.abspath('database.db')) as conn:\n",
    "#         cursor = conn.cursor()\n",
    "#         cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name=?\", (mytable,))\n",
    "#         if cursor.fetchone() is not None:\n",
    "#             print(f'Reading {mytable} from database...')\n",
    "#             query = f'SELECT * FROM {mytable}' \n",
    "#             df = pd.read_sql_query(query, conn)\n",
    "#         else:\n",
    "#             print(f\"{mytable} dataset doesn't exist so generating one...\")\n",
    "#             df = get_emotions_df(model, key)\n",
    "#             df.to_sql('emotions', conn, if_exists = 'replace', index=False)\n",
    "#     return df\n",
    "\n",
    "\n",
    "def check_data_exists(thing, number, update_brand_list, model, key):\n",
    "    with sqlite3.connect(os.path.abspath('database.db')) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name in ('emotions', 'brands', 'association_scores')\")\n",
    "        tables = cursor.fetchall()\n",
    "\n",
    "        if len(tables) == 3:\n",
    "            print('Reading emotions from database...')\n",
    "            emotions_df = pd.read_sql_query(\"SELECT * FROM 'emotions'\", conn) \n",
    "\n",
    "            if update_brand_list == 'no':\n",
    "                print('Reading brands from database...')\n",
    "                brands_df = pd.read_sql_query(\"SELECT * FROM 'brands'\" , conn)\n",
    "                scores_brands = pd.read_sql_query(\"SELECT * FROM 'association_scores'\" , conn)\n",
    "            else:\n",
    "                print('Generating brands data...')\n",
    "                brands_df, scores_brands = get_brands_scores(emotions_df.iloc[:3], model, key)\n",
    "                brands_df.to_sql('brands', conn, if_exists = 'replace', index=False)\n",
    "                scores_brands.to_sql('association_scores', conn, if_exists = 'replace', index=False)\n",
    "        else:\n",
    "            print(\"The data that I need is not in the 'database.db' so need to get it fresh...\")\n",
    "            emotions_df = get_emotions_df(model, key)\n",
    "            brands_df, scores_brands = get_brands_scores(emotions_df.iloc[:3], model, key)\n",
    "            emotions_df.to_sql('emotions', conn, if_exists = 'replace', index=False)\n",
    "            brands_df.to_sql('brands', conn, if_exists = 'replace', index=False)\n",
    "            scores_brands.to_sql('association_scores', conn, if_exists = 'replace', index=False)\n",
    "        \n",
    "        _,scores_thing = get_scores_thing(thing, emotions_df.iloc[:3], model, key)\n",
    "        result = get_similarity(brands_df, scores_thing, scores_brands, number)\n",
    "    \n",
    "    print(f'Given your favorite book, {thing}, here is the brand(s) I recommend: {result}')\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "mytable = 'emotions'\n",
    "update_brand_list = 'yes'\n",
    "thing = 'summer'\n",
    "number = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading emotions from database...\n",
      "Generating brands data...\n",
      "Given your favorite book, summer, here is the brand(s) I recommend: ['Nike', 'Under Armour']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Nike', 'Under Armour']"
      ]
     },
     "execution_count": 921,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_data_exists(thing, number, update_brand_list, model, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_exists(model, api_key, db_name, update_brand_list):\n",
    "    with sqlite3.connect(os.path.abspath(db_name)) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name in ('emotions', 'brands', 'association_scores')\")\n",
    "        tables = cursor.fetchall()\n",
    "        if len(tables) == 3:\n",
    "            query = \"SELECT * FROM 'emotions'\"\n",
    "            emotions_df = pd.read_sql_query(query, conn) \n",
    "\n",
    "            if update_brand_list == 'no':\n",
    "                print('Reading from database...')\n",
    "                query = \"SELECT * FROM 'association_scores'\" \n",
    "                scores_df = pd.read_sql_query(query, conn)\n",
    "            else:\n",
    "                print('Generating brands data...')\n",
    "                brands, scores_df = get_brands_scores(model, api_key, emotions_df['emotion'][:3])\n",
    "                brands.to_sql('brands', conn, if_exists = 'replace', index=False)\n",
    "                scores_df.to_sql('association_scores', conn, if_exists = 'replace', index=False)\n",
    "\n",
    "        else:\n",
    "            print(\"Brands data doesn't exist so generating...\")\n",
    "            emotions_df = get_emotions_df(model, api_key)\n",
    "            emotions_df.to_sql('emotions', conn, if_exists = 'replace', index=False)\n",
    "\n",
    "            brands, scores_df = get_brands_scores(model, api_key, emotions_df['emotion'][:3])\n",
    "            brands.to_sql('brands', conn, if_exists = 'replace', index=False)\n",
    "            scores_df.to_sql('association_scores', conn, if_exists = 'replace', index=False)\n",
    "\n",
    "    return (emotions_df, scores_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "model = \"gpt-4o-2024-08-06\"\n",
    "api_key=os.environ.get('OPENAI_API_KEY')\n",
    "db_name = 'database.db'\n",
    "update_brand_list = 'no'\n",
    "number = 3\n",
    "thing ='summer'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database: ['emotions', 'brands', 'association_scores']\n"
     ]
    }
   ],
   "source": [
    "with sqlite3.connect(os.path.abspath(db_name)) as conn:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    table_names = [table[0] for table in tables]\n",
    "    print(\"Tables in the database:\", table_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df(thing, model, emotions, api_key)\n",
    "df_cleaned = df.dropna(axis=1)\n",
    "\n",
    "dfs = get_dfs(things, model, emotions, api_key)\n",
    "dfs_cleaned = dfs.dropna(axis=1)\n",
    "\n",
    "\n",
    "result = get_similarity(df_cleaned, dfs_cleaned, number)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>info</th>\n",
       "      <th>scores_info</th>\n",
       "      <th>gpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Founded in 1964, Nike is a multinational corpo...</td>\n",
       "      <td>Nike, as a popular and successful brand, evoke...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Levi's</td>\n",
       "      <td>Founded in 1853, Levi's is renowned for its de...</td>\n",
       "      <td>Levi's is a well-established brand known for i...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ralph Lauren</td>\n",
       "      <td>Established in 1967, Ralph Lauren is a luxury ...</td>\n",
       "      <td>Ralph Lauren, as a renowned fashion brand, is ...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Under Armour</td>\n",
       "      <td>Founded in 1996, Under Armour is a leading bra...</td>\n",
       "      <td>Under Armour is a well-regarded athletic wear ...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Calvin Klein</td>\n",
       "      <td>Launched in 1968, Calvin Klein is an iconic fa...</td>\n",
       "      <td>Calvin Klein, being a renowned fashion brand, ...</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         brand                                               info  \\\n",
       "0   0          Nike  Founded in 1964, Nike is a multinational corpo...   \n",
       "1   1        Levi's  Founded in 1853, Levi's is renowned for its de...   \n",
       "2   2  Ralph Lauren  Established in 1967, Ralph Lauren is a luxury ...   \n",
       "3   3  Under Armour  Founded in 1996, Under Armour is a leading bra...   \n",
       "4   4  Calvin Klein  Launched in 1968, Calvin Klein is an iconic fa...   \n",
       "\n",
       "                                         scores_info                gpt  \n",
       "0  Nike, as a popular and successful brand, evoke...  gpt-4o-2024-08-06  \n",
       "1  Levi's is a well-established brand known for i...  gpt-4o-2024-08-06  \n",
       "2  Ralph Lauren, as a renowned fashion brand, is ...  gpt-4o-2024-08-06  \n",
       "3  Under Armour is a well-regarded athletic wear ...  gpt-4o-2024-08-06  \n",
       "4  Calvin Klein, being a renowned fashion brand, ...  gpt-4o-2024-08-06  "
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with sqlite3.connect(os.path.abspath(db_name)) as conn:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name ='brands';\")\n",
    "    query = \"SELECT * FROM 'brands'\" \n",
    "    df = pd.read_sql_query(query, conn)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
