{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai\n",
    "#!pip install transformers\n",
    "#!pip install torch torchvision\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from io import StringIO\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../key/key.json') as f:\n",
    "    k = json.load(f)['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion_b = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a list of 10 top selling both gender clothing brand names in US and for each brand list 2 single word dominant characteristics of the brand shoppers.\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion_s = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a list of 10 best selling song names and for each song list 2 single word dominant emotions that the song inspires. No singer names.\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = chat_completion_b.choices[0].message.content\n",
    "brands = brands.split('\\n')\n",
    "b = [i for i in brands[1:-1] if i not in ['']]\n",
    "b = [re.sub(r'[^a-zA-Z]','',i) for i in b]\n",
    "b_n = b[::3]\n",
    "b_chr = [i for i in b if i not in b[::3]]\n",
    "b_chr = [tuple(b_chr[i::+1][0:2]) for i in range(0,len(b_chr),2)]\n",
    "d_b = dict(zip(b_n,b_chr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = chat_completion_s.choices[0].message.content\n",
    "songs = songs.split('\\n')\n",
    "s = [i for i in songs[1:-1] if i not in ['']]\n",
    "s = [i.split(':')[-1] for i in s]\n",
    "s = [re.sub(r'[^a-zA-Z]','',i) for i in s]\n",
    "s_n = s[::3]\n",
    "s_chr = [i for i in s if i not in s[::3]]\n",
    "s_chr = [tuple(s_chr[i::+1][0:2]) for i in range(0,len(s_chr),2)]\n",
    "d_s = dict(zip(s_n,s_chr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d_b)\n",
    "d_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove songs and brands with less than 2 adjectives.\n",
    "tuple_size_to_remove = [0,1]\n",
    "d_b = {k: v for k, v in d_b.items() if len(v) not in tuple_size_to_remove}\n",
    "d_s = {k: v for k, v in d_s.items() if len(v) not in tuple_size_to_remove}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "#import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_embeddings(texts):\n",
    "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def average_embedding(embeddings):\n",
    "    return np.mean(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarities = []\n",
    "for adj_A in list(d_b.values()):\n",
    "    avg_embedding_A = average_embedding(get_embeddings(adj_A))\n",
    "    for adj_B in list(d_s.values()):\n",
    "        avg_embedding_B = average_embedding(get_embeddings(adj_B))\n",
    "        similarity_score = cosine_similarity([avg_embedding_A], [avg_embedding_B])[0][0]\n",
    "        similarities.append((adj_A, adj_B, similarity_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(similarities, columns = ['b_chr', 's_em', 'cosine'])\n",
    "inverted_d_b = {v: k for k, v in d_b.items()}\n",
    "inverted_d_s = {v: k for k, v in d_s.items()}\n",
    "df['song'] = df['s_em'].map(inverted_d_s)\n",
    "df['brand'] = df['b_chr'].map(inverted_d_b)\n",
    "df['cosine'] = df['cosine'].apply(lambda x: round(x, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "df = df[['brand','b_chr','song','s_em','cosine']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(['brand','cosine'], ascending = [True, False], inplace = True)\n",
    "df = df.groupby('brand').head(3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(get_embeddings(('joy','happy')),axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding an optimal text embedding:\n",
    "#First embed them since used by most methods\n",
    "# Here, we do need to know the frequency for each of the emotions\n",
    "# we have a small dataset\n",
    "\n",
    "\n",
    "\n",
    "embeddings = [nlp(sentence).vector for sentence in sentences]\n",
    "distance = euclidean_distance(embeddings[0], embeddings[1])\n",
    "print(distance)\n",
    "\n",
    "# OUTPUT\n",
    "1.8646982721454675\n",
    "\n",
    "A = ['satisfied','happy']\n",
    "B= ['Sadness', 'Love', 'Trust']\n",
    "def jaccard_similarity(x,y):\n",
    "  \"\"\" returns the jaccard similarity between two lists \"\"\"\n",
    "  intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "  union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "  return intersection_cardinality/float(union_cardinality)\n",
    "\n",
    "print('Jaccard Similarity:', jaccard_similarity(A,B))\n",
    "\n",
    "\n",
    "#OpenAI example\n",
    "#define 3 categories to be represented to the user as strings in json\n",
    "#class Category(Enum):\n",
    "#    violence = \"violence\"\n",
    "#    sexual = \"sexual\"\n",
    "#    self_harm = \"self_harm\"\n",
    "\n",
    "#defining what my data type looks like so it properly imported and exported as json\n",
    "#class ContentCompliance(BaseModel): \n",
    "#    is_violating: bool  #tell me if there is a violation and if so, classify which one of the category classes\n",
    "#    category: Optional[Category] #the type of the category could be none or category. If non violating, no need to define category\n",
    "#    explanation_if_violating: Optional[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Earlier version where I listed teh emotions as enum\n",
    "\n",
    "# class Char(BaseModel): \n",
    "#     is_char: bool\n",
    "#     characteristic: Optional[Characteristic] ?\n",
    "\n",
    "#List 10 best selling American clothing brands and, for each brand, list which one of the emotions in the given list are most closely associated with.\"\n",
    "client = OpenAI(api_key=k)\n",
    "\n",
    "class Characteristic(Enum):\n",
    "    Happiness = 'Happiness'\n",
    "    Sadness = 'Sadness'\n",
    "    Anger = 'Anger'\n",
    "    Fear = 'Fear'\n",
    "    Surprise = 'Surprise'\n",
    "    Disgust = 'Disgust'\n",
    "    Trust = 'Trust'\n",
    "    Anticipation ='Anticipation'\n",
    "    Joy ='Joy'\n",
    "    Love = 'Love'\n",
    "\n",
    "class BrandAttributes(BaseModel):\n",
    "    brand_name: str = Field(None, description=\" name as str\")\n",
    "    characteristics: List[Characteristic] = Field(None, description=\" list of characteristics as str\")\n",
    "\n",
    "class BrandAttributes(BaseModel):\n",
    "    brand_name: str = Field(None, description=\" name as str\")\n",
    "    characteristics: List[Characteristic] = Field(None, description=\" list of characteristics as str\")\n",
    "\n",
    "class BrandChars(BaseModel):\n",
    "    a: List[BrandAttributes] = Field(None, description=\"List of BrandAttributes\")\n",
    "    \n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Be a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"List 30 best selling American clothing brands and, for each brand, list which one of the emotions in the given list are most closely associated with.\"}\n",
    "    ],\n",
    "    response_format=BrandChars,\n",
    ")\n",
    "\n",
    "out = json.loads(completion.choices[0].message.content)\n",
    "brand_emotions = out\n",
    "out = list(out.values())[0]\n",
    "df_brand = pd.DataFrame(data = [i.values() for i in out], columns = ['Name','characteristic'])\n",
    "df_brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "  \n",
    "# Create feature and target arrays \n",
    "X = df_brand_mb.drop(['Name'], axis =1)\n",
    "y = df_brand_mb['Name'] \n",
    "  \n",
    "# Split into training and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "             X, y, test_size = 0.2, random_state=42) \n",
    "  \n",
    "knn = KNeighborsClassifier(n_neighbors=3) \n",
    "  \n",
    "knn.fit(X_train, y_train) \n",
    "  \n",
    "# Predict on dataset which model has not seen before \n",
    "print(knn.predict(X_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what i initially used to get brands\n",
    "\n",
    "# class Chr_answer(BaseModel):\n",
    "#     Characteristics: List[str] = Field(None, description=\"Brands as a list of strings\")\n",
    "\n",
    "# #few shot prompt with api\n",
    "# completion = client.beta.chat.completions.parse(\n",
    "#     model=\"gpt-4o-2024-08-06\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"Be a helpful assistant.\"},\n",
    "#         {\"role\": \"system\", \"content\": \"Find 10 non-redundant best selling American clothing brands.\"},\n",
    "#         {\"role\": \"system\", \"content\": \"DONT MAKE ANY MISTAKES, check if you did any.\"},\n",
    "#         {\"role\": \"user\", \"content\": \"Give me 10 best selling American clothing brands.\"}\n",
    "#     ],\n",
    "#     response_format=Chr_answer,\n",
    "# )\n",
    "\n",
    "# #you can also proceed from parsed eg json.loads(completion_song.choices[0].message.parsed.json())\n",
    "# out = json.loads(completion.choices[0].message.content)\n",
    "# out = list(out.values())[0]\n",
    "# brands = out\n",
    "# print(brands)\n",
    "# print(len(brands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Goal: Get binary association of 100 brands and 1 book with 50 emotions. Multibinarize and do a correlation. in the example, no correlation with any of the brands\n",
    "# # create a list of 50 human emotions\n",
    "# client = OpenAI(api_key=k)\n",
    "# class Chr_answer(BaseModel):\n",
    "#     Characteristics: List[str] = Field(None, description=\"Emotions as a list of strings\")\n",
    "\n",
    "# #few shot prompt with api\n",
    "# completion = client.beta.chat.completions.parse(\n",
    "#     model=\"gpt-4o-2024-08-06\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"Be a helpful assistant.\"},\n",
    "#         {\"role\": \"system\", \"content\": \"Find 50 non-redundant human emotions. These emotions should be different from one another, meaning that for example, of the emotions 'joy' and 'happiness', only pick one. Of 'Shame' and 'Embarrassment' and of 'Envy' and 'Jealousy', only pick one. So on and so forth.\"},\n",
    "#         {\"role\": \"system\", \"content\": \"Stop finding if you've already found 50.\"},\n",
    "#         {\"role\": \"system\", \"content\": \"DONT MAKE ANY MISTAKES, check if you did any.\"},\n",
    "#         {\"role\": \"user\", \"content\": \"Give me about 50 emotions addressing non-redundant and different human feelings.\"}\n",
    "#     ],\n",
    "#     response_format=Chr_answer,\n",
    "# )\n",
    "\n",
    "# #you can also proceed from parsed eg json.loads(completion_song.choices[0].message.parsed.json())\n",
    "# out = json.loads(completion.choices[0].message.content)\n",
    "# out = list(out.values())[0]\n",
    "# emotions = out\n",
    "# print(emotions)\n",
    "# print(len(emotions))\n",
    "\n",
    "# #List 100 best selling American clothing brands and, for each brand, list which one of the emotions in the given list are most closely associated with (Either associated or not, binary).\"\n",
    "# client = OpenAI(api_key=k)\n",
    "\n",
    "# Characteristic = Enum('Characteristic', dict([(i, i) for i in emotions])) #MyEnumType = Enum('MyEnumType', myEnumStrings)\n",
    "\n",
    "# class BrandAttributes(BaseModel):\n",
    "#     brand_name: str = Field(None, description=\" name as str\")\n",
    "#     characteristics: List[Characteristic] = Field(None, description=\" list of characteristics as str\")\n",
    "\n",
    "# class BrandChars(BaseModel):\n",
    "#     a: List[BrandAttributes] = Field(None, description=\"List of BrandAttributes\")\n",
    "    \n",
    "# completion = client.beta.chat.completions.parse(\n",
    "#     model=\"gpt-4o-2024-08-06\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"Be a helpful assistant.\"},\n",
    "#         {\"role\": \"system\", \"content\": \"List 100 best selling American clothing brands and, for each brand, list which one of the emotions in the given list are most closely associated with.\"},\n",
    "#         {\"role\": \"user\", \"content\": \"List 100 best selling American clothing brands and, for each brand, list which one of the emotions in the given list are most closely associated with.\"}\n",
    "#     ],\n",
    "#     response_format=BrandChars,\n",
    "# )\n",
    "\n",
    "# out = json.loads(completion.choices[0].message.content)\n",
    "# brand_emotions = out\n",
    "# out = list(out.values())[0]\n",
    "# df_brand = pd.DataFrame(data = [i.values() for i in out], columns = ['Name','characteristic'])\n",
    "# df_brand\n",
    "\n",
    "# #Take the example song, and list which one of the emotions in the given list are most closely associated with the song.\")\n",
    "\n",
    "# client = OpenAI(api_key=k)\n",
    "\n",
    "# Characteristic = Enum('Characteristic', dict([(i, i) for i in emotions])) \n",
    "\n",
    "# class BookAttributes(BaseModel):\n",
    "#     book_name: str\n",
    "#     book_writer :str = Field(None, description=\"writer as str\")\n",
    "#     characteristics: List[Characteristic]\n",
    "\n",
    "# class BooksChars(BaseModel):\n",
    "#     a: List[BookAttributes] = Field(None, description=\"List of book attributes.\")\n",
    "\n",
    "# prompt = \"\"\"\n",
    "# As prompt, take the book 'Summer Island', list its writer, and a list of the emotions from the given list that are most closely associated with the book.\n",
    "# \"\"\"\n",
    "\n",
    "# completion = client.beta.chat.completions.parse(\n",
    "#     model=\"gpt-4o-2024-08-06\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"Be a helpful assistant.\"},\n",
    "#         {\"role\": \"user\", \"content\": prompt}\n",
    "#     ],\n",
    "#     response_format=BooksChars,\n",
    "# )\n",
    "# out = json.loads(completion.choices[0].message.content)\n",
    "# out = list(out.values())[0]\n",
    "# df_book = pd.DataFrame(data = [i.values() for i in out], columns = ['Name','Writer', 'characteristic'])\n",
    "# df_book\n",
    "\n",
    "# #MultilabelBinarize brands and song\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# mlb = MultiLabelBinarizer(classes=emotions)\n",
    "\n",
    "# df_brand2 = pd.DataFrame(mlb.fit_transform(df_brand['characteristic']), columns = emotions)\n",
    "# df_brand_mb = pd.merge(df_brand2, df_brand[['Name']], how ='left', left_index=True, right_index=True)\n",
    "# df_brand_mb.head()\n",
    "\n",
    "# mlb = MultiLabelBinarizer(classes=emotions)\n",
    "\n",
    "# df_book2 = pd.DataFrame(mlb.fit_transform(df_book['characteristic']), columns = emotions)\n",
    "# df_book_mb = pd.merge(df_book2, df_book[['Name']], how ='left', left_index=True, right_index=True)\n",
    "# df_book_mb.head()\n",
    "\n",
    "# df_b_T = df_brand_mb.set_index('Name').T\n",
    "# df_bo_T = df_book_mb.set_index('Name').T\n",
    "\n",
    "# df_bo_T\n",
    "\n",
    "\n",
    "# df_b_T.corrwith(df_bo_T, axis = 1)\n",
    "\n",
    "\n",
    "#---------------\n",
    "#2nd method, I tried, was to go through every brand from 10, and every emotion from 50, for every pair assign an association value (0 to 500):\n",
    "\n",
    "# # Prompt GPT to determine the association between brand and emotion pairs based on semantic or contextual understanding.\n",
    "  \n",
    "# # Define the Pydantic models for the input and output\n",
    "# class ObjectPair(BaseModel):\n",
    "#     object1: str\n",
    "#     object2: str\n",
    "\n",
    "# class RelationRequest(BaseModel):\n",
    "#     list1: List[str]  # First list of objects\n",
    "#     list2: List[str]  # Second list of objects\n",
    "#     model: str = Field(default=\"gpt-4o-2024-08-06\")  # OpenAI model version\n",
    "#     min_value: float = 0  # Minimum value of the normalized range\n",
    "#     max_value: float = 500  # Maximum value of the normalized range \n",
    "\n",
    "# class RelationResponse(BaseModel):\n",
    "#     pair: ObjectPair\n",
    "#     association_score: float  # The score provided by GPT\n",
    "\n",
    "# class OpenAIRelationQuantifier:\n",
    "#     @staticmethod\n",
    "#     def _generate_prompt(pair: ObjectPair, min_value: float, max_value: float) -> str:\n",
    "#         \"\"\"Generate the prompt for GPT to evaluate the association between two objects.\"\"\"\n",
    "#         return f\"On a scale from {min_value} to {max_value}, how strongly are the following two items related?\\n\\n\" \\\n",
    "#                f\"Item 1: {pair.object1}\\nItem 2: {pair.object2}\\n\" \\\n",
    "#                f\"Please provide a score and a short explanation of their relationship.\"\n",
    "\n",
    "#     @staticmethod\n",
    "#     def quantify_relations(request: RelationRequest) -> List[RelationResponse]:\n",
    "#         \"\"\"Quantify the relationships between each pair of objects using GPT.\"\"\"\n",
    "#         client = OpenAI(api_key=k)  \n",
    "\n",
    "#         results = []\n",
    "#         for object1 in request.list1:\n",
    "#             for object2 in request.list2:\n",
    "#                 pair = ObjectPair(object1=object1, object2=object2)\n",
    "#                 prompt = OpenAIRelationQuantifier._generate_prompt(pair, request.min_value, request.max_value)\n",
    "\n",
    "#                 # Send the prompt to GPT using beta.chat.completions.parse method\n",
    "#                 response = client.beta.chat.completions.parse(\n",
    "#                     model=request.model,\n",
    "#                     messages=[\n",
    "#                         {\"role\": \"system\", \"content\": \"You are an expert at analyzing relationships between concepts.\"},\n",
    "#                         {\"role\": \"user\", \"content\": prompt}\n",
    "#                     ]\n",
    "#                 )\n",
    "\n",
    "#                 # Extract GPT's parsed response\n",
    "#                 gpt_reply = response.choices[0].message.content\n",
    "#                 score_line = gpt_reply.splitlines()[0]\n",
    "#                 score = float(score_line.split()[-1].rstrip('.'))  # Assumes the score is at the end of the first line\n",
    "\n",
    "#                 # Append the result\n",
    "#                 results.append(RelationResponse(pair=pair, association_score=score))\n",
    "\n",
    "#         return results\n",
    "\n",
    "# # Usage\n",
    "\n",
    "# # Define two lists of objects to compare\n",
    "# list1 = brands[:3]\n",
    "# list2 = emotions[:5]\n",
    "\n",
    "# # Create the relation request object\n",
    "# relation_request = RelationRequest(list1=list1, list2=list2, min_value=0, max_value=500)\n",
    "\n",
    "# # Quantify the relationships between objects in the two lists\n",
    "# relations = OpenAIRelationQuantifier.quantify_relations(relation_request)\n",
    "\n",
    "# # Display the results\n",
    "# for relation in relations:\n",
    "#     print(f\"Pair: ({relation.pair.object1}, {relation.pair.object2}) - Association Score: {relation.association_score:.2f}\")\n",
    "# relations\n",
    "\n",
    "\n",
    "# df=pd.DataFrame()\n",
    "# df['brand']= [i.pair.object1 for i in relations]\n",
    "# df['emotion']= [i.pair.object2 for i in relations]\n",
    "# df['score']= [i.association_score for i in relations]\n",
    "\n",
    "# print(df)\n",
    "# df = df.pivot(index='brand',columns ='emotion', values='score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #nested prompt as dict\n",
    "# from pydantic import BaseModel, Field\n",
    "# from typing import Tuple\n",
    "# class RelationRequest(BaseModel):\n",
    "#     list1: List[str]  # First list of objects (object1)\n",
    "#     list2: List[str]  # Second list of objects (object2)\n",
    "#     model: str = Field(default=\"gpt-4o-2024-08-06\")  # Updated OpenAI model version\n",
    "#     min_value: float = 0  # Minimum value of the normalized range\n",
    "#     max_value: float = 500  # Maximum value of the normalized range (set to 500)\n",
    "\n",
    "# class ObjectPair(BaseModel):\n",
    "#     object1: str\n",
    "#     obj2: str\n",
    "\n",
    "# class RelationResponse(BaseModel):\n",
    "#     pair: ObjectPair\n",
    "#     association_score: float  # The score provided by GPT\n",
    "\n",
    "\n",
    "# class OpenAIRelationQuantifier:\n",
    "#     @staticmethod\n",
    "#     def _generate_prompt(object1: str, object2_list: List[str], min_value: float, max_value: float) -> str:\n",
    "#         \"\"\"Generate the prompt for GPT to evaluate the association between one object and a list of other objects.\"\"\"\n",
    "#         prompt = f\"For the object '{object1}', please provide a score between {min_value} and {max_value} for its association with each of the following objects:\"\n",
    "        \n",
    "#         for idx, obj2 in enumerate(object2_list, 1):\n",
    "#             prompt += f\"\\n{idx}. {obj2}\"\n",
    "#             print(obj2)\n",
    "\n",
    "#         prompt += \"\\n\\nReturn the result as 'object1, obj2' pairs and their associated scores\"\n",
    "\n",
    "#         return prompt\n",
    "\n",
    "#     @staticmethod\n",
    "#     def quantify_relations(request: RelationRequest, api_key: str) -> List[RelationResponse]:\n",
    "#         \"\"\"Quantify the relationships between each object1 and all objects in object2 using GPT.\"\"\"\n",
    "#         openai.api_key = api_key  # Set the API key for OpenAI\n",
    "\n",
    "#         results = []\n",
    "#         for object1 in request.list1:\n",
    "#             prompt = OpenAIRelationQuantifier._generate_prompt(object1, request.list2, request.min_value, request.max_value)\n",
    "\n",
    "#             # Send the prompt to GPT\n",
    "#             response = client.beta.chat.completions.parse(\n",
    "#                 model='gpt-4o-2024-08-06',\n",
    "#                 messages=[\n",
    "#                     {\"role\": \"system\", \"content\": \"You are an expert at analyzing relationships between concepts.\"},\n",
    "#                     {\"role\": \"user\", \"content\": prompt}\n",
    "#                 ],\n",
    "#                 response_format=RelationResponse\n",
    "#             )\n",
    "\n",
    "#             # Extract GPT's parsed response\n",
    "#             results.append(response.choices[0].message.content)\n",
    "#         return results\n",
    "\n",
    "\n",
    "# api_key = k\n",
    "\n",
    "# # Define two lists of objects to compare\n",
    "# list1 = brands[:3]\n",
    "# list2 = emotions[:2]\n",
    "\n",
    "# # Create the relation request object\n",
    "# relation_request = RelationRequest(list1=list1, list2=list2, min_value=0, max_value=500)\n",
    "\n",
    "# # Quantify the relationships between objects in the two lists\n",
    "# relations = OpenAIRelationQuantifier.quantify_relations(relation_request, api_key=api_key)\n",
    "\n",
    "# relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #nested prompt as joined str in a list\n",
    "# class RelationRequest(BaseModel):\n",
    "#     list1: List[str]  # First list of objects (object1)\n",
    "#     list2: List[str]  # Second list of objects (object2)\n",
    "#     model: str = Field(default=\"gpt-4o-2024-08-06\")  # Updated OpenAI model version\n",
    "#     min_value: float = 0  # Minimum value of the normalized range\n",
    "#     max_value: float = 500  # Maximum value of the normalized range (set to 500)\n",
    "\n",
    "# class ObjectPair(BaseModel):\n",
    "#     object1: str\n",
    "#     obj2: str\n",
    "\n",
    "# class RelationResponse(BaseModel):\n",
    "#     pair: ObjectPair\n",
    "#     association_score: float  # The score provided by GPT\n",
    "\n",
    "# class OpenAIRelationQuantifier:\n",
    "#     @staticmethod\n",
    "#     def _generate_prompt(object1: str, object2_list: List[str], min_value: float, max_value: float) -> str:\n",
    "#         \"\"\"Generate the prompt for GPT to evaluate the association between one object and a list of other objects.\"\"\"\n",
    "#         object2_str = ', '.join(object2_list)\n",
    "#         return f\"For the following object '{object1}', assign a score between {min_value} and {max_value} to each object in this list: [{object2_str}]. \" \\\n",
    "#                f\"Please return the result as 'object1 obj2' pairs, and ensure the scores reflect the association strength.\"\n",
    "\n",
    "#     @staticmethod\n",
    "#     def quantify_relations(request: RelationRequest, api_key: str) -> List[RelationResponse]:\n",
    "#         \"\"\"Quantify the relationships between each object1 and all objects in object2 using GPT.\"\"\"\n",
    "#         openai.api_key = api_key  # Set the API key for OpenAI\n",
    "\n",
    "#         results = []\n",
    "#         for object1 in request.list1:\n",
    "#             prompt = OpenAIRelationQuantifier._generate_prompt(object1, request.list2, request.min_value, request.max_value)\n",
    "\n",
    "#             response = client.beta.chat.completions.parse(\n",
    "#                 model=request.model,\n",
    "#                 messages=[\n",
    "#                     {\"role\": \"system\", \"content\": \"You are an expert at analyzing relationships between concepts.\"},\n",
    "#                     {\"role\": \"user\", \"content\": prompt}\n",
    "#                 ],\n",
    "#                 response_format=RelationResponse\n",
    "#             )\n",
    "            \n",
    "#             results.append(relations.choices[0].message.content)\n",
    "\n",
    "#         return results\n",
    "\n",
    "\n",
    "# api_key = k\n",
    "\n",
    "# # Define two lists of objects to compare\n",
    "# list1 = [\"Nike\", \"lululemon\"]\n",
    "# list2 = [\"Joy\",\"liberated\"]\n",
    "\n",
    "# # Create the relation request object\n",
    "# relation_request = RelationRequest(list1=list1, list2=list2, min_value=0, max_value=500)\n",
    "\n",
    "# # Quantify the relationships between objects in the two lists\n",
    "# relations = OpenAIRelationQuantifier.quantify_relations(relation_request, api_key=api_key)\n",
    "# relations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
